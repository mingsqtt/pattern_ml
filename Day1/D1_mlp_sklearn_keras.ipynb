{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.000e+00 1.480e+02 7.200e+01 3.500e+01 0.000e+00 3.360e+01 6.270e-01\n",
      "  5.000e+01]\n",
      " [1.000e+00 8.500e+01 6.600e+01 2.900e+01 0.000e+00 2.660e+01 3.510e-01\n",
      "  3.100e+01]\n",
      " [8.000e+00 1.830e+02 6.400e+01 0.000e+00 0.000e+00 2.330e+01 6.720e-01\n",
      "  3.200e+01]\n",
      " [1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
      "  2.100e+01]\n",
      " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
      "  3.300e+01]]\n",
      "[1. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# load pima indians dataset\n",
    "dataset = np.loadtxt(\"d:/projects/pattern_ml/Day1/data/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "print(X[:5])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1/3,random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.    120.     80.     48.    200.     38.9     1.162  41.   ]\n",
      " [  8.     74.     70.     40.     49.     35.3     0.705  39.   ]\n",
      " [  6.    134.     70.     23.    130.     35.4     0.542  29.   ]\n",
      " [  2.     81.     60.     22.      0.     27.7     0.29   25.   ]\n",
      " [  2.    106.     64.     35.    119.     30.5     1.4    34.   ]]\n",
      "[[-0.85857046 -0.01518682  0.56460661  1.76951504  1.15667283  0.8552722\n",
      "   2.0175701   0.66924232]\n",
      " [ 1.23470609 -1.47510523  0.03438177  1.25503935 -0.25552637  0.39949629\n",
      "   0.66845268  0.49609827]\n",
      " [ 0.63662707  0.42913617  0.03438177  0.16177849  0.50201095  0.41215673\n",
      "   0.18725762 -0.36962196]\n",
      " [-0.55953095 -1.25294374 -0.49584308  0.09746903 -0.71378969 -0.5626973\n",
      "  -0.55667584 -0.71591005]\n",
      " [-0.55953095 -0.45950982 -0.28375314  0.93349204  0.39913551 -0.20820492\n",
      "   2.72017393  0.06323816]]\n"
     ]
    }
   ],
   "source": [
    "#Normalization (z-score)\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "print(X_train[:5])\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  \n",
    "\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.97322078\n",
      "Iteration 2, loss = 0.95988981\n",
      "Iteration 3, loss = 0.94696938\n",
      "Iteration 4, loss = 0.93513825\n",
      "Iteration 5, loss = 0.92364982\n",
      "Iteration 6, loss = 0.91253170\n",
      "Iteration 7, loss = 0.90252676\n",
      "Iteration 8, loss = 0.89203360\n",
      "Iteration 9, loss = 0.88301304\n",
      "Iteration 10, loss = 0.87440040\n",
      "Iteration 11, loss = 0.86560356\n",
      "Iteration 12, loss = 0.85744149\n",
      "Iteration 13, loss = 0.84999216\n",
      "Iteration 14, loss = 0.84251866\n",
      "Iteration 15, loss = 0.83473714\n",
      "Iteration 16, loss = 0.82785462\n",
      "Iteration 17, loss = 0.82033614\n",
      "Iteration 18, loss = 0.81305501\n",
      "Iteration 19, loss = 0.80620462\n",
      "Iteration 20, loss = 0.79849013\n",
      "Iteration 21, loss = 0.79150308\n",
      "Iteration 22, loss = 0.78417821\n",
      "Iteration 23, loss = 0.77650951\n",
      "Iteration 24, loss = 0.76918459\n",
      "Iteration 25, loss = 0.76178319\n",
      "Iteration 26, loss = 0.75447200\n",
      "Iteration 27, loss = 0.74629910\n",
      "Iteration 28, loss = 0.73865381\n",
      "Iteration 29, loss = 0.73028236\n",
      "Iteration 30, loss = 0.72224070\n",
      "Iteration 31, loss = 0.71389669\n",
      "Iteration 32, loss = 0.70542319\n",
      "Iteration 33, loss = 0.69688676\n",
      "Iteration 34, loss = 0.68828719\n",
      "Iteration 35, loss = 0.67961597\n",
      "Iteration 36, loss = 0.67076347\n",
      "Iteration 37, loss = 0.66204940\n",
      "Iteration 38, loss = 0.65355249\n",
      "Iteration 39, loss = 0.64486780\n",
      "Iteration 40, loss = 0.63640102\n",
      "Iteration 41, loss = 0.62803643\n",
      "Iteration 42, loss = 0.62045133\n",
      "Iteration 43, loss = 0.61229658\n",
      "Iteration 44, loss = 0.60485894\n",
      "Iteration 45, loss = 0.59780246\n",
      "Iteration 46, loss = 0.59061317\n",
      "Iteration 47, loss = 0.58377517\n",
      "Iteration 48, loss = 0.57728248\n",
      "Iteration 49, loss = 0.57115525\n",
      "Iteration 50, loss = 0.56475005\n",
      "Iteration 51, loss = 0.55906514\n",
      "Iteration 52, loss = 0.55346272\n",
      "Iteration 53, loss = 0.54802671\n",
      "Iteration 54, loss = 0.54272841\n",
      "Iteration 55, loss = 0.53786397\n",
      "Iteration 56, loss = 0.53303808\n",
      "Iteration 57, loss = 0.52884302\n",
      "Iteration 58, loss = 0.52441022\n",
      "Iteration 59, loss = 0.52032160\n",
      "Iteration 60, loss = 0.51679343\n",
      "Iteration 61, loss = 0.51333405\n",
      "Iteration 62, loss = 0.51010604\n",
      "Iteration 63, loss = 0.50684709\n",
      "Iteration 64, loss = 0.50420433\n",
      "Iteration 65, loss = 0.50152167\n",
      "Iteration 66, loss = 0.49921913\n",
      "Iteration 67, loss = 0.49698742\n",
      "Iteration 68, loss = 0.49489976\n",
      "Iteration 69, loss = 0.49307351\n",
      "Iteration 70, loss = 0.49141553\n",
      "Iteration 71, loss = 0.48982240\n",
      "Iteration 72, loss = 0.48828115\n",
      "Iteration 73, loss = 0.48698881\n",
      "Iteration 74, loss = 0.48562060\n",
      "Iteration 75, loss = 0.48428578\n",
      "Iteration 76, loss = 0.48311958\n",
      "Iteration 77, loss = 0.48199288\n",
      "Iteration 78, loss = 0.48090050\n",
      "Iteration 79, loss = 0.47983109\n",
      "Iteration 80, loss = 0.47882411\n",
      "Iteration 81, loss = 0.47783371\n",
      "Iteration 82, loss = 0.47693768\n",
      "Iteration 83, loss = 0.47592582\n",
      "Iteration 84, loss = 0.47507382\n",
      "Iteration 85, loss = 0.47418199\n",
      "Iteration 86, loss = 0.47333565\n",
      "Iteration 87, loss = 0.47259377\n",
      "Iteration 88, loss = 0.47183884\n",
      "Iteration 89, loss = 0.47098866\n",
      "Iteration 90, loss = 0.47024399\n",
      "Iteration 91, loss = 0.46954564\n",
      "Iteration 92, loss = 0.46879219\n",
      "Iteration 93, loss = 0.46810958\n",
      "Iteration 94, loss = 0.46754365\n",
      "Iteration 95, loss = 0.46683437\n",
      "Iteration 96, loss = 0.46617937\n",
      "Iteration 97, loss = 0.46552179\n",
      "Iteration 98, loss = 0.46491522\n",
      "Iteration 99, loss = 0.46430953\n",
      "Iteration 100, loss = 0.46362507\n",
      "Iteration 101, loss = 0.46296770\n",
      "Iteration 102, loss = 0.46232234\n",
      "Iteration 103, loss = 0.46169617\n",
      "Iteration 104, loss = 0.46107242\n",
      "Iteration 105, loss = 0.46055720\n",
      "Iteration 106, loss = 0.45991559\n",
      "Iteration 107, loss = 0.45934618\n",
      "Iteration 108, loss = 0.45880702\n",
      "Iteration 109, loss = 0.45822215\n",
      "Iteration 110, loss = 0.45768643\n",
      "Iteration 111, loss = 0.45715229\n",
      "Iteration 112, loss = 0.45655551\n",
      "Iteration 113, loss = 0.45615201\n",
      "Iteration 114, loss = 0.45556501\n",
      "Iteration 115, loss = 0.45504432\n",
      "Iteration 116, loss = 0.45460375\n",
      "Iteration 117, loss = 0.45402917\n",
      "Iteration 118, loss = 0.45354069\n",
      "Iteration 119, loss = 0.45303927\n",
      "Iteration 120, loss = 0.45255844\n",
      "Iteration 121, loss = 0.45220107\n",
      "Iteration 122, loss = 0.45170323\n",
      "Iteration 123, loss = 0.45127446\n",
      "Iteration 124, loss = 0.45078780\n",
      "Iteration 125, loss = 0.45038594\n",
      "Iteration 126, loss = 0.44994631\n",
      "Iteration 127, loss = 0.44952265\n",
      "Iteration 128, loss = 0.44914783\n",
      "Iteration 129, loss = 0.44868152\n",
      "Iteration 130, loss = 0.44826609\n",
      "Iteration 131, loss = 0.44781593\n",
      "Iteration 132, loss = 0.44740812\n",
      "Iteration 133, loss = 0.44693068\n",
      "Iteration 134, loss = 0.44658251\n",
      "Iteration 135, loss = 0.44609537\n",
      "Iteration 136, loss = 0.44566766\n",
      "Iteration 137, loss = 0.44531054\n",
      "Iteration 138, loss = 0.44481574\n",
      "Iteration 139, loss = 0.44440465\n",
      "Iteration 140, loss = 0.44401022\n",
      "Iteration 141, loss = 0.44353902\n",
      "Iteration 142, loss = 0.44319257\n",
      "Iteration 143, loss = 0.44281928\n",
      "Iteration 144, loss = 0.44241613\n",
      "Iteration 145, loss = 0.44212228\n",
      "Iteration 146, loss = 0.44173973\n",
      "Iteration 147, loss = 0.44136622\n",
      "Iteration 148, loss = 0.44103728\n",
      "Iteration 149, loss = 0.44064530\n",
      "Iteration 150, loss = 0.44028226\n",
      "Iteration 151, loss = 0.43990062\n",
      "Iteration 152, loss = 0.43970285\n",
      "Iteration 153, loss = 0.43917988\n",
      "Iteration 154, loss = 0.43888414\n",
      "Iteration 155, loss = 0.43856669\n",
      "Iteration 156, loss = 0.43820331\n",
      "Iteration 157, loss = 0.43790621\n",
      "Iteration 158, loss = 0.43754476\n",
      "Iteration 159, loss = 0.43724331\n",
      "Iteration 160, loss = 0.43694490\n",
      "Iteration 161, loss = 0.43662318\n",
      "Iteration 162, loss = 0.43629846\n",
      "Iteration 163, loss = 0.43599955\n",
      "Iteration 164, loss = 0.43568411\n",
      "Iteration 165, loss = 0.43537323\n",
      "Iteration 166, loss = 0.43507536\n",
      "Iteration 167, loss = 0.43471108\n",
      "Iteration 168, loss = 0.43443423\n",
      "Iteration 169, loss = 0.43409020\n",
      "Iteration 170, loss = 0.43386094\n",
      "Iteration 171, loss = 0.43351377\n",
      "Iteration 172, loss = 0.43318683\n",
      "Iteration 173, loss = 0.43293521\n",
      "Iteration 174, loss = 0.43262828\n",
      "Iteration 175, loss = 0.43236331\n",
      "Iteration 176, loss = 0.43217780\n",
      "Iteration 177, loss = 0.43179437\n",
      "Iteration 178, loss = 0.43155829\n",
      "Iteration 179, loss = 0.43124906\n",
      "Iteration 180, loss = 0.43104353\n",
      "Iteration 181, loss = 0.43071988\n",
      "Iteration 182, loss = 0.43047779\n",
      "Iteration 183, loss = 0.43023410\n",
      "Iteration 184, loss = 0.42998972\n",
      "Iteration 185, loss = 0.42977599\n",
      "Iteration 186, loss = 0.42946644\n",
      "Iteration 187, loss = 0.42926955\n",
      "Iteration 188, loss = 0.42912853\n",
      "Iteration 189, loss = 0.42873324\n",
      "Iteration 190, loss = 0.42853384\n",
      "Iteration 191, loss = 0.42825586\n",
      "Iteration 192, loss = 0.42806584\n",
      "Iteration 193, loss = 0.42783083\n",
      "Iteration 194, loss = 0.42754329\n",
      "Iteration 195, loss = 0.42727003\n",
      "Iteration 196, loss = 0.42703018\n",
      "Iteration 197, loss = 0.42683207\n",
      "Iteration 198, loss = 0.42651674\n",
      "Iteration 199, loss = 0.42636329\n",
      "Iteration 200, loss = 0.42604227\n",
      "Iteration 201, loss = 0.42584464\n",
      "Iteration 202, loss = 0.42561613\n",
      "Iteration 203, loss = 0.42544722\n",
      "Iteration 204, loss = 0.42517597\n",
      "Iteration 205, loss = 0.42498874\n",
      "Iteration 206, loss = 0.42483211\n",
      "Iteration 207, loss = 0.42460139\n",
      "Iteration 208, loss = 0.42438869\n",
      "Iteration 209, loss = 0.42420565\n",
      "Iteration 210, loss = 0.42396546\n",
      "Iteration 211, loss = 0.42377680\n",
      "Iteration 212, loss = 0.42362287\n",
      "Iteration 213, loss = 0.42341311\n",
      "Iteration 214, loss = 0.42326482\n",
      "Iteration 215, loss = 0.42304766\n",
      "Iteration 216, loss = 0.42282571\n",
      "Iteration 217, loss = 0.42269307\n",
      "Iteration 218, loss = 0.42252377\n",
      "Iteration 219, loss = 0.42229005\n",
      "Iteration 220, loss = 0.42208944\n",
      "Iteration 221, loss = 0.42190722\n",
      "Iteration 222, loss = 0.42187767\n",
      "Iteration 223, loss = 0.42170495\n",
      "Iteration 224, loss = 0.42142194\n",
      "Iteration 225, loss = 0.42125064\n",
      "Iteration 226, loss = 0.42106249\n",
      "Iteration 227, loss = 0.42091820\n",
      "Iteration 228, loss = 0.42069362\n",
      "Iteration 229, loss = 0.42053504\n",
      "Iteration 230, loss = 0.42035315\n",
      "Iteration 231, loss = 0.42015880\n",
      "Iteration 232, loss = 0.42002494\n",
      "Iteration 233, loss = 0.41980816\n",
      "Iteration 234, loss = 0.41961428\n",
      "Iteration 235, loss = 0.41943357\n",
      "Iteration 236, loss = 0.41921355\n",
      "Iteration 237, loss = 0.41900960\n",
      "Iteration 238, loss = 0.41885845\n",
      "Iteration 239, loss = 0.41864382\n",
      "Iteration 240, loss = 0.41845025\n",
      "Iteration 241, loss = 0.41829279\n",
      "Iteration 242, loss = 0.41813555\n",
      "Iteration 243, loss = 0.41791045\n",
      "Iteration 244, loss = 0.41771741\n",
      "Iteration 245, loss = 0.41762581\n",
      "Iteration 246, loss = 0.41741214\n",
      "Iteration 247, loss = 0.41726905\n",
      "Iteration 248, loss = 0.41702469\n",
      "Iteration 249, loss = 0.41689193\n",
      "Iteration 250, loss = 0.41671713\n",
      "Iteration 251, loss = 0.41657748\n",
      "Iteration 252, loss = 0.41640489\n",
      "Iteration 253, loss = 0.41626339\n",
      "Iteration 254, loss = 0.41606951\n",
      "Iteration 255, loss = 0.41589908\n",
      "Iteration 256, loss = 0.41570794\n",
      "Iteration 257, loss = 0.41555605\n",
      "Iteration 258, loss = 0.41534177\n",
      "Iteration 259, loss = 0.41522726\n",
      "Iteration 260, loss = 0.41502543\n",
      "Iteration 261, loss = 0.41488896\n",
      "Iteration 262, loss = 0.41470697\n",
      "Iteration 263, loss = 0.41456068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 264, loss = 0.41438753\n",
      "Iteration 265, loss = 0.41424758\n",
      "Iteration 266, loss = 0.41411542\n",
      "Iteration 267, loss = 0.41398358\n",
      "Iteration 268, loss = 0.41379740\n",
      "Iteration 269, loss = 0.41363968\n",
      "Iteration 270, loss = 0.41354960\n",
      "Iteration 271, loss = 0.41338211\n",
      "Iteration 272, loss = 0.41328001\n",
      "Iteration 273, loss = 0.41304033\n",
      "Iteration 274, loss = 0.41287382\n",
      "Iteration 275, loss = 0.41275028\n",
      "Iteration 276, loss = 0.41256006\n",
      "Iteration 277, loss = 0.41255830\n",
      "Iteration 278, loss = 0.41241358\n",
      "Iteration 279, loss = 0.41215903\n",
      "Iteration 280, loss = 0.41199883\n",
      "Iteration 281, loss = 0.41193085\n",
      "Iteration 282, loss = 0.41169869\n",
      "Iteration 283, loss = 0.41151206\n",
      "Iteration 284, loss = 0.41136012\n",
      "Iteration 285, loss = 0.41124075\n",
      "Iteration 286, loss = 0.41108913\n",
      "Iteration 287, loss = 0.41091715\n",
      "Iteration 288, loss = 0.41084325\n",
      "Iteration 289, loss = 0.41069099\n",
      "Iteration 290, loss = 0.41053339\n",
      "Iteration 291, loss = 0.41044987\n",
      "Iteration 292, loss = 0.41037120\n",
      "Iteration 293, loss = 0.41019787\n",
      "Iteration 294, loss = 0.41002917\n",
      "Iteration 295, loss = 0.41002297\n",
      "Iteration 296, loss = 0.40980260\n",
      "Iteration 297, loss = 0.40975312\n",
      "Iteration 298, loss = 0.40960032\n",
      "Iteration 299, loss = 0.40937368\n",
      "Iteration 300, loss = 0.40915184\n",
      "Iteration 301, loss = 0.40905884\n",
      "Iteration 302, loss = 0.40895130\n",
      "Iteration 303, loss = 0.40876060\n",
      "Iteration 304, loss = 0.40858553\n",
      "Iteration 305, loss = 0.40849375\n",
      "Iteration 306, loss = 0.40832964\n",
      "Iteration 307, loss = 0.40817305\n",
      "Iteration 308, loss = 0.40814321\n",
      "Iteration 309, loss = 0.40797663\n",
      "Iteration 310, loss = 0.40779664\n",
      "Iteration 311, loss = 0.40774941\n",
      "Iteration 312, loss = 0.40763097\n",
      "Iteration 313, loss = 0.40742061\n",
      "Iteration 314, loss = 0.40732899\n",
      "Iteration 315, loss = 0.40715946\n",
      "Iteration 316, loss = 0.40701327\n",
      "Iteration 317, loss = 0.40681163\n",
      "Iteration 318, loss = 0.40671811\n",
      "Iteration 319, loss = 0.40657699\n",
      "Iteration 320, loss = 0.40640171\n",
      "Iteration 321, loss = 0.40626807\n",
      "Iteration 322, loss = 0.40623122\n",
      "Iteration 323, loss = 0.40607145\n",
      "Iteration 324, loss = 0.40591128\n",
      "Iteration 325, loss = 0.40572081\n",
      "Iteration 326, loss = 0.40558456\n",
      "Iteration 327, loss = 0.40548636\n",
      "Iteration 328, loss = 0.40533710\n",
      "Iteration 329, loss = 0.40516747\n",
      "Iteration 330, loss = 0.40509861\n",
      "Iteration 331, loss = 0.40485418\n",
      "Iteration 332, loss = 0.40469091\n",
      "Iteration 333, loss = 0.40459658\n",
      "Iteration 334, loss = 0.40439249\n",
      "Iteration 335, loss = 0.40421824\n",
      "Iteration 336, loss = 0.40408527\n",
      "Iteration 337, loss = 0.40391375\n",
      "Iteration 338, loss = 0.40371095\n",
      "Iteration 339, loss = 0.40365101\n",
      "Iteration 340, loss = 0.40343619\n",
      "Iteration 341, loss = 0.40324607\n",
      "Iteration 342, loss = 0.40313333\n",
      "Iteration 343, loss = 0.40303994\n",
      "Iteration 344, loss = 0.40281010\n",
      "Iteration 345, loss = 0.40274613\n",
      "Iteration 346, loss = 0.40253549\n",
      "Iteration 347, loss = 0.40235445\n",
      "Iteration 348, loss = 0.40216739\n",
      "Iteration 349, loss = 0.40202987\n",
      "Iteration 350, loss = 0.40187201\n",
      "Iteration 351, loss = 0.40171221\n",
      "Iteration 352, loss = 0.40157486\n",
      "Iteration 353, loss = 0.40149444\n",
      "Iteration 354, loss = 0.40120285\n",
      "Iteration 355, loss = 0.40107662\n",
      "Iteration 356, loss = 0.40087848\n",
      "Iteration 357, loss = 0.40075166\n",
      "Iteration 358, loss = 0.40047150\n",
      "Iteration 359, loss = 0.40038200\n",
      "Iteration 360, loss = 0.40012516\n",
      "Iteration 361, loss = 0.39996210\n",
      "Iteration 362, loss = 0.39983473\n",
      "Iteration 363, loss = 0.39963681\n",
      "Iteration 364, loss = 0.39941884\n",
      "Iteration 365, loss = 0.39929325\n",
      "Iteration 366, loss = 0.39917781\n",
      "Iteration 367, loss = 0.39898447\n",
      "Iteration 368, loss = 0.39879624\n",
      "Iteration 369, loss = 0.39867378\n",
      "Iteration 370, loss = 0.39847938\n",
      "Iteration 371, loss = 0.39835421\n",
      "Iteration 372, loss = 0.39819716\n",
      "Iteration 373, loss = 0.39803991\n",
      "Iteration 374, loss = 0.39792199\n",
      "Iteration 375, loss = 0.39771457\n",
      "Iteration 376, loss = 0.39753832\n",
      "Iteration 377, loss = 0.39743809\n",
      "Iteration 378, loss = 0.39726390\n",
      "Iteration 379, loss = 0.39707111\n",
      "Iteration 380, loss = 0.39702177\n",
      "Iteration 381, loss = 0.39684406\n",
      "Iteration 382, loss = 0.39667953\n",
      "Iteration 383, loss = 0.39650965\n",
      "Iteration 384, loss = 0.39631985\n",
      "Iteration 385, loss = 0.39626428\n",
      "Iteration 386, loss = 0.39606407\n",
      "Iteration 387, loss = 0.39600080\n",
      "Iteration 388, loss = 0.39592057\n",
      "Iteration 389, loss = 0.39580708\n",
      "Iteration 390, loss = 0.39564546\n",
      "Iteration 391, loss = 0.39546049\n",
      "Iteration 392, loss = 0.39531692\n",
      "Iteration 393, loss = 0.39517120\n",
      "Iteration 394, loss = 0.39501167\n",
      "Iteration 395, loss = 0.39498241\n",
      "Iteration 396, loss = 0.39472792\n",
      "Iteration 397, loss = 0.39462306\n",
      "Iteration 398, loss = 0.39454053\n",
      "Iteration 399, loss = 0.39437000\n",
      "Iteration 400, loss = 0.39424720\n",
      "Iteration 401, loss = 0.39404380\n",
      "Iteration 402, loss = 0.39406238\n",
      "Iteration 403, loss = 0.39372684\n",
      "Iteration 404, loss = 0.39363998\n",
      "Iteration 405, loss = 0.39353113\n",
      "Iteration 406, loss = 0.39343961\n",
      "Iteration 407, loss = 0.39333147\n",
      "Iteration 408, loss = 0.39316507\n",
      "Iteration 409, loss = 0.39305918\n",
      "Iteration 410, loss = 0.39288165\n",
      "Iteration 411, loss = 0.39271450\n",
      "Iteration 412, loss = 0.39255063\n",
      "Iteration 413, loss = 0.39251510\n",
      "Iteration 414, loss = 0.39234437\n",
      "Iteration 415, loss = 0.39221346\n",
      "Iteration 416, loss = 0.39210620\n",
      "Iteration 417, loss = 0.39191051\n",
      "Iteration 418, loss = 0.39173732\n",
      "Iteration 419, loss = 0.39161322\n",
      "Iteration 420, loss = 0.39149522\n",
      "Iteration 421, loss = 0.39141829\n",
      "Iteration 422, loss = 0.39118794\n",
      "Iteration 423, loss = 0.39121954\n",
      "Iteration 424, loss = 0.39107935\n",
      "Iteration 425, loss = 0.39095922\n",
      "Iteration 426, loss = 0.39080134\n",
      "Iteration 427, loss = 0.39067558\n",
      "Iteration 428, loss = 0.39053514\n",
      "Iteration 429, loss = 0.39039863\n",
      "Iteration 430, loss = 0.39024744\n",
      "Iteration 431, loss = 0.39021915\n",
      "Iteration 432, loss = 0.39001414\n",
      "Iteration 433, loss = 0.38987298\n",
      "Iteration 434, loss = 0.38981006\n",
      "Iteration 435, loss = 0.38973688\n",
      "Iteration 436, loss = 0.38949777\n",
      "Iteration 437, loss = 0.38937224\n",
      "Iteration 438, loss = 0.38934160\n",
      "Iteration 439, loss = 0.38916071\n",
      "Iteration 440, loss = 0.38907414\n",
      "Iteration 441, loss = 0.38894780\n",
      "Iteration 442, loss = 0.38887895\n",
      "Iteration 443, loss = 0.38861589\n",
      "Iteration 444, loss = 0.38850182\n",
      "Iteration 445, loss = 0.38836278\n",
      "Iteration 446, loss = 0.38829484\n",
      "Iteration 447, loss = 0.38816236\n",
      "Iteration 448, loss = 0.38802865\n",
      "Iteration 449, loss = 0.38792179\n",
      "Iteration 450, loss = 0.38777626\n",
      "Iteration 451, loss = 0.38771778\n",
      "Iteration 452, loss = 0.38758305\n",
      "Iteration 453, loss = 0.38740355\n",
      "Iteration 454, loss = 0.38729518\n",
      "Iteration 455, loss = 0.38718805\n",
      "Iteration 456, loss = 0.38700084\n",
      "Iteration 457, loss = 0.38685725\n",
      "Iteration 458, loss = 0.38675552\n",
      "Iteration 459, loss = 0.38672594\n",
      "Iteration 460, loss = 0.38657650\n",
      "Iteration 461, loss = 0.38645927\n",
      "Iteration 462, loss = 0.38652916\n",
      "Iteration 463, loss = 0.38623622\n",
      "Iteration 464, loss = 0.38602712\n",
      "Iteration 465, loss = 0.38594353\n",
      "Iteration 466, loss = 0.38595736\n",
      "Iteration 467, loss = 0.38580707\n",
      "Iteration 468, loss = 0.38566498\n",
      "Iteration 469, loss = 0.38552875\n",
      "Iteration 470, loss = 0.38541253\n",
      "Iteration 471, loss = 0.38528949\n",
      "Iteration 472, loss = 0.38522365\n",
      "Iteration 473, loss = 0.38503178\n",
      "Iteration 474, loss = 0.38501165\n",
      "Iteration 475, loss = 0.38480191\n",
      "Iteration 476, loss = 0.38468854\n",
      "Iteration 477, loss = 0.38453257\n",
      "Iteration 478, loss = 0.38444584\n",
      "Iteration 479, loss = 0.38433243\n",
      "Iteration 480, loss = 0.38429326\n",
      "Iteration 481, loss = 0.38411330\n",
      "Iteration 482, loss = 0.38400542\n",
      "Iteration 483, loss = 0.38385769\n",
      "Iteration 484, loss = 0.38379833\n",
      "Iteration 485, loss = 0.38367470\n",
      "Iteration 486, loss = 0.38356551\n",
      "Iteration 487, loss = 0.38343384\n",
      "Iteration 488, loss = 0.38333653\n",
      "Iteration 489, loss = 0.38330086\n",
      "Iteration 490, loss = 0.38312355\n",
      "Iteration 491, loss = 0.38301351\n",
      "Iteration 492, loss = 0.38294738\n",
      "Iteration 493, loss = 0.38288971\n",
      "Iteration 494, loss = 0.38273842\n",
      "Iteration 495, loss = 0.38264052\n",
      "Iteration 496, loss = 0.38247777\n",
      "Iteration 497, loss = 0.38240640\n",
      "Iteration 498, loss = 0.38229000\n",
      "Iteration 499, loss = 0.38219216\n",
      "Iteration 500, loss = 0.38202719\n",
      "Iteration 501, loss = 0.38196679\n",
      "Iteration 502, loss = 0.38186839\n",
      "Iteration 503, loss = 0.38176205\n",
      "Iteration 504, loss = 0.38156456\n",
      "Iteration 505, loss = 0.38148838\n",
      "Iteration 506, loss = 0.38142845\n",
      "Iteration 507, loss = 0.38133038\n",
      "Iteration 508, loss = 0.38124171\n",
      "Iteration 509, loss = 0.38105107\n",
      "Iteration 510, loss = 0.38107032\n",
      "Iteration 511, loss = 0.38089308\n",
      "Iteration 512, loss = 0.38081503\n",
      "Iteration 513, loss = 0.38060319\n",
      "Iteration 514, loss = 0.38051854\n",
      "Iteration 515, loss = 0.38041719\n",
      "Iteration 516, loss = 0.38031500\n",
      "Iteration 517, loss = 0.38025224\n",
      "Iteration 518, loss = 0.38025153\n",
      "Iteration 519, loss = 0.38005752\n",
      "Iteration 520, loss = 0.37998036\n",
      "Iteration 521, loss = 0.37994342\n",
      "Iteration 522, loss = 0.37985947\n",
      "Iteration 523, loss = 0.37964622\n",
      "Iteration 524, loss = 0.37963138\n",
      "Iteration 525, loss = 0.37950172\n",
      "Iteration 526, loss = 0.37945486\n",
      "Iteration 527, loss = 0.37939577\n",
      "Iteration 528, loss = 0.37929307\n",
      "Iteration 529, loss = 0.37916816\n",
      "Iteration 530, loss = 0.37906659\n",
      "Iteration 531, loss = 0.37893002\n",
      "Iteration 532, loss = 0.37888823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 533, loss = 0.37874178\n",
      "Iteration 534, loss = 0.37866820\n",
      "Iteration 535, loss = 0.37858526\n",
      "Iteration 536, loss = 0.37851990\n",
      "Iteration 537, loss = 0.37831424\n",
      "Iteration 538, loss = 0.37831892\n",
      "Iteration 539, loss = 0.37827099\n",
      "Iteration 540, loss = 0.37813690\n",
      "Iteration 541, loss = 0.37803319\n",
      "Iteration 542, loss = 0.37790532\n",
      "Iteration 543, loss = 0.37784312\n",
      "Iteration 544, loss = 0.37772207\n",
      "Iteration 545, loss = 0.37756056\n",
      "Iteration 546, loss = 0.37750475\n",
      "Iteration 547, loss = 0.37735116\n",
      "Iteration 548, loss = 0.37721971\n",
      "Iteration 549, loss = 0.37717700\n",
      "Iteration 550, loss = 0.37701783\n",
      "Iteration 551, loss = 0.37696410\n",
      "Iteration 552, loss = 0.37686855\n",
      "Iteration 553, loss = 0.37679974\n",
      "Iteration 554, loss = 0.37670151\n",
      "Iteration 555, loss = 0.37659743\n",
      "Iteration 556, loss = 0.37648293\n",
      "Iteration 557, loss = 0.37636831\n",
      "Iteration 558, loss = 0.37629268\n",
      "Iteration 559, loss = 0.37621170\n",
      "Iteration 560, loss = 0.37608436\n",
      "Iteration 561, loss = 0.37602412\n",
      "Iteration 562, loss = 0.37588529\n",
      "Iteration 563, loss = 0.37586722\n",
      "Iteration 564, loss = 0.37567332\n",
      "Iteration 565, loss = 0.37562302\n",
      "Iteration 566, loss = 0.37555110\n",
      "Iteration 567, loss = 0.37543758\n",
      "Iteration 568, loss = 0.37538406\n",
      "Iteration 569, loss = 0.37529335\n",
      "Iteration 570, loss = 0.37517484\n",
      "Iteration 571, loss = 0.37510291\n",
      "Iteration 572, loss = 0.37499393\n",
      "Iteration 573, loss = 0.37490697\n",
      "Iteration 574, loss = 0.37483100\n",
      "Iteration 575, loss = 0.37492797\n",
      "Iteration 576, loss = 0.37472907\n",
      "Iteration 577, loss = 0.37469945\n",
      "Iteration 578, loss = 0.37454385\n",
      "Iteration 579, loss = 0.37439927\n",
      "Iteration 580, loss = 0.37433895\n",
      "Iteration 581, loss = 0.37422699\n",
      "Iteration 582, loss = 0.37409793\n",
      "Iteration 583, loss = 0.37399087\n",
      "Iteration 584, loss = 0.37384909\n",
      "Iteration 585, loss = 0.37391510\n",
      "Iteration 586, loss = 0.37363384\n",
      "Iteration 587, loss = 0.37353776\n",
      "Iteration 588, loss = 0.37342073\n",
      "Iteration 589, loss = 0.37332664\n",
      "Iteration 590, loss = 0.37324732\n",
      "Iteration 591, loss = 0.37307820\n",
      "Iteration 592, loss = 0.37299298\n",
      "Iteration 593, loss = 0.37285339\n",
      "Iteration 594, loss = 0.37276168\n",
      "Iteration 595, loss = 0.37264697\n",
      "Iteration 596, loss = 0.37258489\n",
      "Iteration 597, loss = 0.37260474\n",
      "Iteration 598, loss = 0.37228763\n",
      "Iteration 599, loss = 0.37224969\n",
      "Iteration 600, loss = 0.37212099\n",
      "Iteration 601, loss = 0.37209048\n",
      "Iteration 602, loss = 0.37190583\n",
      "Iteration 603, loss = 0.37184157\n",
      "Iteration 604, loss = 0.37180458\n",
      "Iteration 605, loss = 0.37160237\n",
      "Iteration 606, loss = 0.37151496\n",
      "Iteration 607, loss = 0.37143958\n",
      "Iteration 608, loss = 0.37129411\n",
      "Iteration 609, loss = 0.37123739\n",
      "Iteration 610, loss = 0.37111125\n",
      "Iteration 611, loss = 0.37104742\n",
      "Iteration 612, loss = 0.37091483\n",
      "Iteration 613, loss = 0.37079808\n",
      "Iteration 614, loss = 0.37075488\n",
      "Iteration 615, loss = 0.37071418\n",
      "Iteration 616, loss = 0.37052397\n",
      "Iteration 617, loss = 0.37038581\n",
      "Iteration 618, loss = 0.37024158\n",
      "Iteration 619, loss = 0.37016220\n",
      "Iteration 620, loss = 0.37009939\n",
      "Iteration 621, loss = 0.37001557\n",
      "Iteration 622, loss = 0.37007242\n",
      "Iteration 623, loss = 0.36983694\n",
      "Iteration 624, loss = 0.36979025\n",
      "Iteration 625, loss = 0.36955594\n",
      "Iteration 626, loss = 0.36941353\n",
      "Iteration 627, loss = 0.36936741\n",
      "Iteration 628, loss = 0.36931317\n",
      "Iteration 629, loss = 0.36912343\n",
      "Iteration 630, loss = 0.36903120\n",
      "Iteration 631, loss = 0.36900390\n",
      "Iteration 632, loss = 0.36892650\n",
      "Iteration 633, loss = 0.36878885\n",
      "Iteration 634, loss = 0.36867700\n",
      "Iteration 635, loss = 0.36854068\n",
      "Iteration 636, loss = 0.36847942\n",
      "Iteration 637, loss = 0.36831441\n",
      "Iteration 638, loss = 0.36823993\n",
      "Iteration 639, loss = 0.36819454\n",
      "Iteration 640, loss = 0.36805367\n",
      "Iteration 641, loss = 0.36801652\n",
      "Iteration 642, loss = 0.36806547\n",
      "Iteration 643, loss = 0.36773533\n",
      "Iteration 644, loss = 0.36765614\n",
      "Iteration 645, loss = 0.36757620\n",
      "Iteration 646, loss = 0.36751774\n",
      "Iteration 647, loss = 0.36751430\n",
      "Iteration 648, loss = 0.36733252\n",
      "Iteration 649, loss = 0.36724274\n",
      "Iteration 650, loss = 0.36711571\n",
      "Iteration 651, loss = 0.36696866\n",
      "Iteration 652, loss = 0.36682327\n",
      "Iteration 653, loss = 0.36668341\n",
      "Iteration 654, loss = 0.36659557\n",
      "Iteration 655, loss = 0.36648368\n",
      "Iteration 656, loss = 0.36635993\n",
      "Iteration 657, loss = 0.36623059\n",
      "Iteration 658, loss = 0.36619824\n",
      "Iteration 659, loss = 0.36603455\n",
      "Iteration 660, loss = 0.36592842\n",
      "Iteration 661, loss = 0.36576569\n",
      "Iteration 662, loss = 0.36583490\n",
      "Iteration 663, loss = 0.36563212\n",
      "Iteration 664, loss = 0.36543640\n",
      "Iteration 665, loss = 0.36535204\n",
      "Iteration 666, loss = 0.36527605\n",
      "Iteration 667, loss = 0.36517712\n",
      "Iteration 668, loss = 0.36495185\n",
      "Iteration 669, loss = 0.36489827\n",
      "Iteration 670, loss = 0.36474768\n",
      "Iteration 671, loss = 0.36465505\n",
      "Iteration 672, loss = 0.36452824\n",
      "Iteration 673, loss = 0.36444638\n",
      "Iteration 674, loss = 0.36422207\n",
      "Iteration 675, loss = 0.36423767\n",
      "Iteration 676, loss = 0.36413185\n",
      "Iteration 677, loss = 0.36397608\n",
      "Iteration 678, loss = 0.36384533\n",
      "Iteration 679, loss = 0.36369977\n",
      "Iteration 680, loss = 0.36362946\n",
      "Iteration 681, loss = 0.36347119\n",
      "Iteration 682, loss = 0.36328068\n",
      "Iteration 683, loss = 0.36321986\n",
      "Iteration 684, loss = 0.36308821\n",
      "Iteration 685, loss = 0.36292468\n",
      "Iteration 686, loss = 0.36295965\n",
      "Iteration 687, loss = 0.36275444\n",
      "Iteration 688, loss = 0.36268770\n",
      "Iteration 689, loss = 0.36242555\n",
      "Iteration 690, loss = 0.36231129\n",
      "Iteration 691, loss = 0.36215213\n",
      "Iteration 692, loss = 0.36203223\n",
      "Iteration 693, loss = 0.36188301\n",
      "Iteration 694, loss = 0.36175320\n",
      "Iteration 695, loss = 0.36160408\n",
      "Iteration 696, loss = 0.36142628\n",
      "Iteration 697, loss = 0.36133271\n",
      "Iteration 698, loss = 0.36113518\n",
      "Iteration 699, loss = 0.36097331\n",
      "Iteration 700, loss = 0.36083599\n",
      "Iteration 701, loss = 0.36086750\n",
      "Iteration 702, loss = 0.36047909\n",
      "Iteration 703, loss = 0.36033689\n",
      "Iteration 704, loss = 0.36013713\n",
      "Iteration 705, loss = 0.35997655\n",
      "Iteration 706, loss = 0.35985086\n",
      "Iteration 707, loss = 0.35970149\n",
      "Iteration 708, loss = 0.35960068\n",
      "Iteration 709, loss = 0.35950971\n",
      "Iteration 710, loss = 0.35919002\n",
      "Iteration 711, loss = 0.35914522\n",
      "Iteration 712, loss = 0.35883143\n",
      "Iteration 713, loss = 0.35860009\n",
      "Iteration 714, loss = 0.35845147\n",
      "Iteration 715, loss = 0.35832051\n",
      "Iteration 716, loss = 0.35802524\n",
      "Iteration 717, loss = 0.35792715\n",
      "Iteration 718, loss = 0.35759634\n",
      "Iteration 719, loss = 0.35744110\n",
      "Iteration 720, loss = 0.35730771\n",
      "Iteration 721, loss = 0.35706258\n",
      "Iteration 722, loss = 0.35686087\n",
      "Iteration 723, loss = 0.35664922\n",
      "Iteration 724, loss = 0.35648891\n",
      "Iteration 725, loss = 0.35634459\n",
      "Iteration 726, loss = 0.35615723\n",
      "Iteration 727, loss = 0.35602310\n",
      "Iteration 728, loss = 0.35589338\n",
      "Iteration 729, loss = 0.35561948\n",
      "Iteration 730, loss = 0.35544696\n",
      "Iteration 731, loss = 0.35522959\n",
      "Iteration 732, loss = 0.35505433\n",
      "Iteration 733, loss = 0.35489218\n",
      "Iteration 734, loss = 0.35474004\n",
      "Iteration 735, loss = 0.35459741\n",
      "Iteration 736, loss = 0.35443836\n",
      "Iteration 737, loss = 0.35422394\n",
      "Iteration 738, loss = 0.35403052\n",
      "Iteration 739, loss = 0.35388562\n",
      "Iteration 740, loss = 0.35372951\n",
      "Iteration 741, loss = 0.35369200\n",
      "Iteration 742, loss = 0.35350709\n",
      "Iteration 743, loss = 0.35333249\n",
      "Iteration 744, loss = 0.35316423\n",
      "Iteration 745, loss = 0.35312120\n",
      "Iteration 746, loss = 0.35292074\n",
      "Iteration 747, loss = 0.35278823\n",
      "Iteration 748, loss = 0.35261921\n",
      "Iteration 749, loss = 0.35238384\n",
      "Iteration 750, loss = 0.35236871\n",
      "Iteration 751, loss = 0.35242297\n",
      "Iteration 752, loss = 0.35197227\n",
      "Iteration 753, loss = 0.35187978\n",
      "Iteration 754, loss = 0.35183555\n",
      "Iteration 755, loss = 0.35164887\n",
      "Iteration 756, loss = 0.35170630\n",
      "Iteration 757, loss = 0.35146912\n",
      "Iteration 758, loss = 0.35124367\n",
      "Iteration 759, loss = 0.35109510\n",
      "Iteration 760, loss = 0.35095308\n",
      "Iteration 761, loss = 0.35104090\n",
      "Iteration 762, loss = 0.35077961\n",
      "Iteration 763, loss = 0.35069535\n",
      "Iteration 764, loss = 0.35047659\n",
      "Iteration 765, loss = 0.35043537\n",
      "Iteration 766, loss = 0.35025938\n",
      "Iteration 767, loss = 0.35019369\n",
      "Iteration 768, loss = 0.34993600\n",
      "Iteration 769, loss = 0.34998850\n",
      "Iteration 770, loss = 0.34974612\n",
      "Iteration 771, loss = 0.34974815\n",
      "Iteration 772, loss = 0.34954973\n",
      "Iteration 773, loss = 0.34943876\n",
      "Iteration 774, loss = 0.34927054\n",
      "Iteration 775, loss = 0.34912331\n",
      "Iteration 776, loss = 0.34906167\n",
      "Iteration 777, loss = 0.34884981\n",
      "Iteration 778, loss = 0.34872128\n",
      "Iteration 779, loss = 0.34868329\n",
      "Iteration 780, loss = 0.34861078\n",
      "Iteration 781, loss = 0.34830002\n",
      "Iteration 782, loss = 0.34820428\n",
      "Iteration 783, loss = 0.34806175\n",
      "Iteration 784, loss = 0.34794095\n",
      "Iteration 785, loss = 0.34778348\n",
      "Iteration 786, loss = 0.34768333\n",
      "Iteration 787, loss = 0.34768779\n",
      "Iteration 788, loss = 0.34755086\n",
      "Iteration 789, loss = 0.34729356\n",
      "Iteration 790, loss = 0.34716792\n",
      "Iteration 791, loss = 0.34709371\n",
      "Iteration 792, loss = 0.34692430\n",
      "Iteration 793, loss = 0.34681058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 794, loss = 0.34672184\n",
      "Iteration 795, loss = 0.34656332\n",
      "Iteration 796, loss = 0.34641869\n",
      "Iteration 797, loss = 0.34640541\n",
      "Iteration 798, loss = 0.34612975\n",
      "Iteration 799, loss = 0.34600064\n",
      "Iteration 800, loss = 0.34597493\n",
      "Iteration 801, loss = 0.34568861\n",
      "Iteration 802, loss = 0.34567285\n",
      "Iteration 803, loss = 0.34552155\n",
      "Iteration 804, loss = 0.34534079\n",
      "Iteration 805, loss = 0.34523188\n",
      "Iteration 806, loss = 0.34502728\n",
      "Iteration 807, loss = 0.34496497\n",
      "Iteration 808, loss = 0.34481233\n",
      "Iteration 809, loss = 0.34469697\n",
      "Iteration 810, loss = 0.34450499\n",
      "Iteration 811, loss = 0.34449743\n",
      "Iteration 812, loss = 0.34437663\n",
      "Iteration 813, loss = 0.34412181\n",
      "Iteration 814, loss = 0.34399674\n",
      "Iteration 815, loss = 0.34392707\n",
      "Iteration 816, loss = 0.34377765\n",
      "Iteration 817, loss = 0.34355836\n",
      "Iteration 818, loss = 0.34344623\n",
      "Iteration 819, loss = 0.34329954\n",
      "Iteration 820, loss = 0.34311932\n",
      "Iteration 821, loss = 0.34301380\n",
      "Iteration 822, loss = 0.34289942\n",
      "Iteration 823, loss = 0.34275591\n",
      "Iteration 824, loss = 0.34272065\n",
      "Iteration 825, loss = 0.34258500\n",
      "Iteration 826, loss = 0.34237850\n",
      "Iteration 827, loss = 0.34220799\n",
      "Iteration 828, loss = 0.34208900\n",
      "Iteration 829, loss = 0.34197180\n",
      "Iteration 830, loss = 0.34185527\n",
      "Iteration 831, loss = 0.34179734\n",
      "Iteration 832, loss = 0.34158276\n",
      "Iteration 833, loss = 0.34135086\n",
      "Iteration 834, loss = 0.34113134\n",
      "Iteration 835, loss = 0.34110616\n",
      "Iteration 836, loss = 0.34099991\n",
      "Iteration 837, loss = 0.34089724\n",
      "Iteration 838, loss = 0.34088725\n",
      "Iteration 839, loss = 0.34061711\n",
      "Iteration 840, loss = 0.34041568\n",
      "Iteration 841, loss = 0.34036029\n",
      "Iteration 842, loss = 0.34014282\n",
      "Iteration 843, loss = 0.34002928\n",
      "Iteration 844, loss = 0.33994146\n",
      "Iteration 845, loss = 0.33970393\n",
      "Iteration 846, loss = 0.33956969\n",
      "Iteration 847, loss = 0.33954936\n",
      "Iteration 848, loss = 0.33924029\n",
      "Iteration 849, loss = 0.33913821\n",
      "Iteration 850, loss = 0.33904730\n",
      "Iteration 851, loss = 0.33878684\n",
      "Iteration 852, loss = 0.33861103\n",
      "Iteration 853, loss = 0.33863475\n",
      "Iteration 854, loss = 0.33854381\n",
      "Iteration 855, loss = 0.33830575\n",
      "Iteration 856, loss = 0.33804015\n",
      "Iteration 857, loss = 0.33785317\n",
      "Iteration 858, loss = 0.33764612\n",
      "Iteration 859, loss = 0.33748168\n",
      "Iteration 860, loss = 0.33742255\n",
      "Iteration 861, loss = 0.33726304\n",
      "Iteration 862, loss = 0.33733311\n",
      "Iteration 863, loss = 0.33692497\n",
      "Iteration 864, loss = 0.33681007\n",
      "Iteration 865, loss = 0.33664534\n",
      "Iteration 866, loss = 0.33658174\n",
      "Iteration 867, loss = 0.33641703\n",
      "Iteration 868, loss = 0.33633329\n",
      "Iteration 869, loss = 0.33614069\n",
      "Iteration 870, loss = 0.33601983\n",
      "Iteration 871, loss = 0.33585405\n",
      "Iteration 872, loss = 0.33572224\n",
      "Iteration 873, loss = 0.33558197\n",
      "Iteration 874, loss = 0.33556645\n",
      "Iteration 875, loss = 0.33548395\n",
      "Iteration 876, loss = 0.33537223\n",
      "Iteration 877, loss = 0.33518732\n",
      "Iteration 878, loss = 0.33491663\n",
      "Iteration 879, loss = 0.33499565\n",
      "Iteration 880, loss = 0.33485646\n",
      "Iteration 881, loss = 0.33459438\n",
      "Iteration 882, loss = 0.33450993\n",
      "Iteration 883, loss = 0.33431182\n",
      "Iteration 884, loss = 0.33411765\n",
      "Iteration 885, loss = 0.33402349\n",
      "Iteration 886, loss = 0.33385237\n",
      "Iteration 887, loss = 0.33378053\n",
      "Iteration 888, loss = 0.33371445\n",
      "Iteration 889, loss = 0.33343828\n",
      "Iteration 890, loss = 0.33354319\n",
      "Iteration 891, loss = 0.33326161\n",
      "Iteration 892, loss = 0.33309867\n",
      "Iteration 893, loss = 0.33294549\n",
      "Iteration 894, loss = 0.33288905\n",
      "Iteration 895, loss = 0.33274093\n",
      "Iteration 896, loss = 0.33265243\n",
      "Iteration 897, loss = 0.33251816\n",
      "Iteration 898, loss = 0.33237368\n",
      "Iteration 899, loss = 0.33223825\n",
      "Iteration 900, loss = 0.33211724\n",
      "Iteration 901, loss = 0.33193905\n",
      "Iteration 902, loss = 0.33197862\n",
      "Iteration 903, loss = 0.33174614\n",
      "Iteration 904, loss = 0.33160468\n",
      "Iteration 905, loss = 0.33143452\n",
      "Iteration 906, loss = 0.33129806\n",
      "Iteration 907, loss = 0.33125298\n",
      "Iteration 908, loss = 0.33110424\n",
      "Iteration 909, loss = 0.33091112\n",
      "Iteration 910, loss = 0.33075708\n",
      "Iteration 911, loss = 0.33069341\n",
      "Iteration 912, loss = 0.33063726\n",
      "Iteration 913, loss = 0.33051383\n",
      "Iteration 914, loss = 0.33039151\n",
      "Iteration 915, loss = 0.33020396\n",
      "Iteration 916, loss = 0.33007765\n",
      "Iteration 917, loss = 0.33005168\n",
      "Iteration 918, loss = 0.32989473\n",
      "Iteration 919, loss = 0.32982049\n",
      "Iteration 920, loss = 0.32966545\n",
      "Iteration 921, loss = 0.32951179\n",
      "Iteration 922, loss = 0.32941597\n",
      "Iteration 923, loss = 0.32927153\n",
      "Iteration 924, loss = 0.32911742\n",
      "Iteration 925, loss = 0.32906028\n",
      "Iteration 926, loss = 0.32888966\n",
      "Iteration 927, loss = 0.32885773\n",
      "Iteration 928, loss = 0.32869891\n",
      "Iteration 929, loss = 0.32860394\n",
      "Iteration 930, loss = 0.32847547\n",
      "Iteration 931, loss = 0.32833445\n",
      "Iteration 932, loss = 0.32844982\n",
      "Iteration 933, loss = 0.32814000\n",
      "Iteration 934, loss = 0.32800159\n",
      "Iteration 935, loss = 0.32786667\n",
      "Iteration 936, loss = 0.32780398\n",
      "Iteration 937, loss = 0.32766438\n",
      "Iteration 938, loss = 0.32759983\n",
      "Iteration 939, loss = 0.32746286\n",
      "Iteration 940, loss = 0.32733140\n",
      "Iteration 941, loss = 0.32717013\n",
      "Iteration 942, loss = 0.32707568\n",
      "Iteration 943, loss = 0.32707262\n",
      "Iteration 944, loss = 0.32691558\n",
      "Iteration 945, loss = 0.32678101\n",
      "Iteration 946, loss = 0.32668398\n",
      "Iteration 947, loss = 0.32656337\n",
      "Iteration 948, loss = 0.32646833\n",
      "Iteration 949, loss = 0.32636536\n",
      "Iteration 950, loss = 0.32634684\n",
      "Iteration 951, loss = 0.32619447\n",
      "Iteration 952, loss = 0.32602565\n",
      "Iteration 953, loss = 0.32590218\n",
      "Iteration 954, loss = 0.32587719\n",
      "Iteration 955, loss = 0.32560066\n",
      "Iteration 956, loss = 0.32573183\n",
      "Iteration 957, loss = 0.32540213\n",
      "Iteration 958, loss = 0.32535106\n",
      "Iteration 959, loss = 0.32519268\n",
      "Iteration 960, loss = 0.32508536\n",
      "Iteration 961, loss = 0.32499776\n",
      "Iteration 962, loss = 0.32483891\n",
      "Iteration 963, loss = 0.32476656\n",
      "Iteration 964, loss = 0.32455860\n",
      "Iteration 965, loss = 0.32442752\n",
      "Iteration 966, loss = 0.32424481\n",
      "Iteration 967, loss = 0.32417758\n",
      "Iteration 968, loss = 0.32408643\n",
      "Iteration 969, loss = 0.32400878\n",
      "Iteration 970, loss = 0.32377221\n",
      "Iteration 971, loss = 0.32361536\n",
      "Iteration 972, loss = 0.32352090\n",
      "Iteration 973, loss = 0.32333553\n",
      "Iteration 974, loss = 0.32327480\n",
      "Iteration 975, loss = 0.32320218\n",
      "Iteration 976, loss = 0.32305988\n",
      "Iteration 977, loss = 0.32284901\n",
      "Iteration 978, loss = 0.32279743\n",
      "Iteration 979, loss = 0.32262690\n",
      "Iteration 980, loss = 0.32252228\n",
      "Iteration 981, loss = 0.32234609\n",
      "Iteration 982, loss = 0.32227453\n",
      "Iteration 983, loss = 0.32209614\n",
      "Iteration 984, loss = 0.32207240\n",
      "Iteration 985, loss = 0.32185920\n",
      "Iteration 986, loss = 0.32180075\n",
      "Iteration 987, loss = 0.32156004\n",
      "Iteration 988, loss = 0.32151043\n",
      "Iteration 989, loss = 0.32143365\n",
      "Iteration 990, loss = 0.32123287\n",
      "Iteration 991, loss = 0.32111090\n",
      "Iteration 992, loss = 0.32096604\n",
      "Iteration 993, loss = 0.32088456\n",
      "Iteration 994, loss = 0.32075224\n",
      "Iteration 995, loss = 0.32058631\n",
      "Iteration 996, loss = 0.32046039\n",
      "Iteration 997, loss = 0.32031013\n",
      "Iteration 998, loss = 0.32018312\n",
      "Iteration 999, loss = 0.32022443\n",
      "Iteration 1000, loss = 0.31995420\n",
      "Iteration 1001, loss = 0.31982114\n",
      "Iteration 1002, loss = 0.31973075\n",
      "Iteration 1003, loss = 0.31968358\n",
      "Iteration 1004, loss = 0.31944502\n",
      "Iteration 1005, loss = 0.31934934\n",
      "Iteration 1006, loss = 0.31921334\n",
      "Iteration 1007, loss = 0.31912882\n",
      "Iteration 1008, loss = 0.31902158\n",
      "Iteration 1009, loss = 0.31884712\n",
      "Iteration 1010, loss = 0.31876493\n",
      "Iteration 1011, loss = 0.31873599\n",
      "Iteration 1012, loss = 0.31842462\n",
      "Iteration 1013, loss = 0.31830716\n",
      "Iteration 1014, loss = 0.31826735\n",
      "Iteration 1015, loss = 0.31830077\n",
      "Iteration 1016, loss = 0.31807206\n",
      "Iteration 1017, loss = 0.31792715\n",
      "Iteration 1018, loss = 0.31778086\n",
      "Iteration 1019, loss = 0.31768323\n",
      "Iteration 1020, loss = 0.31765572\n",
      "Iteration 1021, loss = 0.31749967\n",
      "Iteration 1022, loss = 0.31741373\n",
      "Iteration 1023, loss = 0.31731579\n",
      "Iteration 1024, loss = 0.31713274\n",
      "Iteration 1025, loss = 0.31705268\n",
      "Iteration 1026, loss = 0.31701718\n",
      "Iteration 1027, loss = 0.31692850\n",
      "Iteration 1028, loss = 0.31681356\n",
      "Iteration 1029, loss = 0.31674043\n",
      "Iteration 1030, loss = 0.31647806\n",
      "Iteration 1031, loss = 0.31638566\n",
      "Iteration 1032, loss = 0.31625692\n",
      "Iteration 1033, loss = 0.31609102\n",
      "Iteration 1034, loss = 0.31601299\n",
      "Iteration 1035, loss = 0.31582106\n",
      "Iteration 1036, loss = 0.31571153\n",
      "Iteration 1037, loss = 0.31558360\n",
      "Iteration 1038, loss = 0.31543794\n",
      "Iteration 1039, loss = 0.31546037\n",
      "Iteration 1040, loss = 0.31530265\n",
      "Iteration 1041, loss = 0.31514476\n",
      "Iteration 1042, loss = 0.31508851\n",
      "Iteration 1043, loss = 0.31513644\n",
      "Iteration 1044, loss = 0.31485837\n",
      "Iteration 1045, loss = 0.31470490\n",
      "Iteration 1046, loss = 0.31461818\n",
      "Iteration 1047, loss = 0.31462470\n",
      "Iteration 1048, loss = 0.31448453\n",
      "Iteration 1049, loss = 0.31444368\n",
      "Iteration 1050, loss = 0.31413398\n",
      "Iteration 1051, loss = 0.31406647\n",
      "Iteration 1052, loss = 0.31393713\n",
      "Iteration 1053, loss = 0.31390707\n",
      "Iteration 1054, loss = 0.31373018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1055, loss = 0.31368421\n",
      "Iteration 1056, loss = 0.31368805\n",
      "Iteration 1057, loss = 0.31349177\n",
      "Iteration 1058, loss = 0.31339516\n",
      "Iteration 1059, loss = 0.31316940\n",
      "Iteration 1060, loss = 0.31306306\n",
      "Iteration 1061, loss = 0.31286118\n",
      "Iteration 1062, loss = 0.31278745\n",
      "Iteration 1063, loss = 0.31270008\n",
      "Iteration 1064, loss = 0.31255744\n",
      "Iteration 1065, loss = 0.31241906\n",
      "Iteration 1066, loss = 0.31235734\n",
      "Iteration 1067, loss = 0.31226298\n",
      "Iteration 1068, loss = 0.31213425\n",
      "Iteration 1069, loss = 0.31197793\n",
      "Iteration 1070, loss = 0.31178978\n",
      "Iteration 1071, loss = 0.31165502\n",
      "Iteration 1072, loss = 0.31159747\n",
      "Iteration 1073, loss = 0.31144006\n",
      "Iteration 1074, loss = 0.31134675\n",
      "Iteration 1075, loss = 0.31122626\n",
      "Iteration 1076, loss = 0.31109502\n",
      "Iteration 1077, loss = 0.31100301\n",
      "Iteration 1078, loss = 0.31082601\n",
      "Iteration 1079, loss = 0.31074821\n",
      "Iteration 1080, loss = 0.31054914\n",
      "Iteration 1081, loss = 0.31062895\n",
      "Iteration 1082, loss = 0.31045784\n",
      "Iteration 1083, loss = 0.31029324\n",
      "Iteration 1084, loss = 0.31020780\n",
      "Iteration 1085, loss = 0.31000930\n",
      "Iteration 1086, loss = 0.30988827\n",
      "Iteration 1087, loss = 0.30985940\n",
      "Iteration 1088, loss = 0.30969948\n",
      "Iteration 1089, loss = 0.30952515\n",
      "Iteration 1090, loss = 0.30951241\n",
      "Iteration 1091, loss = 0.30937880\n",
      "Iteration 1092, loss = 0.30914215\n",
      "Iteration 1093, loss = 0.30911083\n",
      "Iteration 1094, loss = 0.30907012\n",
      "Iteration 1095, loss = 0.30885171\n",
      "Iteration 1096, loss = 0.30877464\n",
      "Iteration 1097, loss = 0.30859321\n",
      "Iteration 1098, loss = 0.30854945\n",
      "Iteration 1099, loss = 0.30853544\n",
      "Iteration 1100, loss = 0.30839649\n",
      "Iteration 1101, loss = 0.30827370\n",
      "Iteration 1102, loss = 0.30816952\n",
      "Iteration 1103, loss = 0.30807660\n",
      "Iteration 1104, loss = 0.30796174\n",
      "Iteration 1105, loss = 0.30783746\n",
      "Iteration 1106, loss = 0.30770316\n",
      "Iteration 1107, loss = 0.30762228\n",
      "Iteration 1108, loss = 0.30747780\n",
      "Iteration 1109, loss = 0.30744537\n",
      "Iteration 1110, loss = 0.30735930\n",
      "Iteration 1111, loss = 0.30714700\n",
      "Iteration 1112, loss = 0.30708767\n",
      "Iteration 1113, loss = 0.30697198\n",
      "Iteration 1114, loss = 0.30692862\n",
      "Iteration 1115, loss = 0.30684727\n",
      "Iteration 1116, loss = 0.30661869\n",
      "Iteration 1117, loss = 0.30645032\n",
      "Iteration 1118, loss = 0.30637288\n",
      "Iteration 1119, loss = 0.30648461\n",
      "Iteration 1120, loss = 0.30633229\n",
      "Iteration 1121, loss = 0.30630577\n",
      "Iteration 1122, loss = 0.30607558\n",
      "Iteration 1123, loss = 0.30598047\n",
      "Iteration 1124, loss = 0.30581429\n",
      "Iteration 1125, loss = 0.30581989\n",
      "Iteration 1126, loss = 0.30566455\n",
      "Iteration 1127, loss = 0.30556418\n",
      "Iteration 1128, loss = 0.30544400\n",
      "Iteration 1129, loss = 0.30544323\n",
      "Iteration 1130, loss = 0.30528833\n",
      "Iteration 1131, loss = 0.30513047\n",
      "Iteration 1132, loss = 0.30502600\n",
      "Iteration 1133, loss = 0.30495499\n",
      "Iteration 1134, loss = 0.30497345\n",
      "Iteration 1135, loss = 0.30477067\n",
      "Iteration 1136, loss = 0.30465357\n",
      "Iteration 1137, loss = 0.30452533\n",
      "Iteration 1138, loss = 0.30445147\n",
      "Iteration 1139, loss = 0.30436801\n",
      "Iteration 1140, loss = 0.30427966\n",
      "Iteration 1141, loss = 0.30421556\n",
      "Iteration 1142, loss = 0.30408230\n",
      "Iteration 1143, loss = 0.30393469\n",
      "Iteration 1144, loss = 0.30384065\n",
      "Iteration 1145, loss = 0.30380924\n",
      "Iteration 1146, loss = 0.30376320\n",
      "Iteration 1147, loss = 0.30371881\n",
      "Iteration 1148, loss = 0.30363633\n",
      "Iteration 1149, loss = 0.30353055\n",
      "Iteration 1150, loss = 0.30339421\n",
      "Iteration 1151, loss = 0.30337571\n",
      "Iteration 1152, loss = 0.30319866\n",
      "Iteration 1153, loss = 0.30304606\n",
      "Iteration 1154, loss = 0.30299286\n",
      "Iteration 1155, loss = 0.30291283\n",
      "Iteration 1156, loss = 0.30275946\n",
      "Iteration 1157, loss = 0.30277161\n",
      "Iteration 1158, loss = 0.30258808\n",
      "Iteration 1159, loss = 0.30248747\n",
      "Iteration 1160, loss = 0.30242966\n",
      "Iteration 1161, loss = 0.30229642\n",
      "Iteration 1162, loss = 0.30219706\n",
      "Iteration 1163, loss = 0.30206504\n",
      "Iteration 1164, loss = 0.30203557\n",
      "Iteration 1165, loss = 0.30204434\n",
      "Iteration 1166, loss = 0.30174599\n",
      "Iteration 1167, loss = 0.30163195\n",
      "Iteration 1168, loss = 0.30163168\n",
      "Iteration 1169, loss = 0.30151137\n",
      "Iteration 1170, loss = 0.30138746\n",
      "Iteration 1171, loss = 0.30134699\n",
      "Iteration 1172, loss = 0.30136512\n",
      "Iteration 1173, loss = 0.30115939\n",
      "Iteration 1174, loss = 0.30110333\n",
      "Iteration 1175, loss = 0.30099378\n",
      "Iteration 1176, loss = 0.30101809\n",
      "Iteration 1177, loss = 0.30075060\n",
      "Iteration 1178, loss = 0.30071472\n",
      "Iteration 1179, loss = 0.30068233\n",
      "Iteration 1180, loss = 0.30070752\n",
      "Iteration 1181, loss = 0.30057439\n",
      "Iteration 1182, loss = 0.30054072\n",
      "Iteration 1183, loss = 0.30027736\n",
      "Iteration 1184, loss = 0.30013324\n",
      "Iteration 1185, loss = 0.30026238\n",
      "Iteration 1186, loss = 0.29996825\n",
      "Iteration 1187, loss = 0.29996430\n",
      "Iteration 1188, loss = 0.29986937\n",
      "Iteration 1189, loss = 0.29974391\n",
      "Iteration 1190, loss = 0.29967233\n",
      "Iteration 1191, loss = 0.29963590\n",
      "Iteration 1192, loss = 0.29947443\n",
      "Iteration 1193, loss = 0.29937144\n",
      "Iteration 1194, loss = 0.29926542\n",
      "Iteration 1195, loss = 0.29925291\n",
      "Iteration 1196, loss = 0.29910357\n",
      "Iteration 1197, loss = 0.29903136\n",
      "Iteration 1198, loss = 0.29908896\n",
      "Iteration 1199, loss = 0.29897413\n",
      "Iteration 1200, loss = 0.29891356\n",
      "Iteration 1201, loss = 0.29879828\n",
      "Iteration 1202, loss = 0.29873402\n",
      "Iteration 1203, loss = 0.29856274\n",
      "Iteration 1204, loss = 0.29846924\n",
      "Iteration 1205, loss = 0.29845976\n",
      "Iteration 1206, loss = 0.29827762\n",
      "Iteration 1207, loss = 0.29812877\n",
      "Iteration 1208, loss = 0.29805064\n",
      "Iteration 1209, loss = 0.29804723\n",
      "Iteration 1210, loss = 0.29798541\n",
      "Iteration 1211, loss = 0.29781920\n",
      "Iteration 1212, loss = 0.29771331\n",
      "Iteration 1213, loss = 0.29768850\n",
      "Iteration 1214, loss = 0.29751353\n",
      "Iteration 1215, loss = 0.29745220\n",
      "Iteration 1216, loss = 0.29737530\n",
      "Iteration 1217, loss = 0.29727861\n",
      "Iteration 1218, loss = 0.29717951\n",
      "Iteration 1219, loss = 0.29702382\n",
      "Iteration 1220, loss = 0.29696037\n",
      "Iteration 1221, loss = 0.29682400\n",
      "Iteration 1222, loss = 0.29676116\n",
      "Iteration 1223, loss = 0.29666771\n",
      "Iteration 1224, loss = 0.29666940\n",
      "Iteration 1225, loss = 0.29659763\n",
      "Iteration 1226, loss = 0.29646359\n",
      "Iteration 1227, loss = 0.29639143\n",
      "Iteration 1228, loss = 0.29627821\n",
      "Iteration 1229, loss = 0.29621037\n",
      "Iteration 1230, loss = 0.29618727\n",
      "Iteration 1231, loss = 0.29608315\n",
      "Iteration 1232, loss = 0.29605122\n",
      "Iteration 1233, loss = 0.29583859\n",
      "Iteration 1234, loss = 0.29579736\n",
      "Iteration 1235, loss = 0.29584483\n",
      "Iteration 1236, loss = 0.29575475\n",
      "Iteration 1237, loss = 0.29554682\n",
      "Iteration 1238, loss = 0.29543513\n",
      "Iteration 1239, loss = 0.29539116\n",
      "Iteration 1240, loss = 0.29531818\n",
      "Iteration 1241, loss = 0.29525392\n",
      "Iteration 1242, loss = 0.29515500\n",
      "Iteration 1243, loss = 0.29519615\n",
      "Iteration 1244, loss = 0.29499960\n",
      "Iteration 1245, loss = 0.29489532\n",
      "Iteration 1246, loss = 0.29479454\n",
      "Iteration 1247, loss = 0.29465201\n",
      "Iteration 1248, loss = 0.29456117\n",
      "Iteration 1249, loss = 0.29449460\n",
      "Iteration 1250, loss = 0.29435641\n",
      "Iteration 1251, loss = 0.29436461\n",
      "Iteration 1252, loss = 0.29444088\n",
      "Iteration 1253, loss = 0.29433395\n",
      "Iteration 1254, loss = 0.29411445\n",
      "Iteration 1255, loss = 0.29428539\n",
      "Iteration 1256, loss = 0.29413508\n",
      "Iteration 1257, loss = 0.29383220\n",
      "Iteration 1258, loss = 0.29369219\n",
      "Iteration 1259, loss = 0.29363407\n",
      "Iteration 1260, loss = 0.29347701\n",
      "Iteration 1261, loss = 0.29348193\n",
      "Iteration 1262, loss = 0.29336841\n",
      "Iteration 1263, loss = 0.29332882\n",
      "Iteration 1264, loss = 0.29315551\n",
      "Iteration 1265, loss = 0.29304123\n",
      "Iteration 1266, loss = 0.29303159\n",
      "Iteration 1267, loss = 0.29288855\n",
      "Iteration 1268, loss = 0.29273960\n",
      "Iteration 1269, loss = 0.29260095\n",
      "Iteration 1270, loss = 0.29251089\n",
      "Iteration 1271, loss = 0.29257822\n",
      "Iteration 1272, loss = 0.29244030\n",
      "Iteration 1273, loss = 0.29247485\n",
      "Iteration 1274, loss = 0.29269941\n",
      "Iteration 1275, loss = 0.29222663\n",
      "Iteration 1276, loss = 0.29214912\n",
      "Iteration 1277, loss = 0.29222761\n",
      "Iteration 1278, loss = 0.29197278\n",
      "Iteration 1279, loss = 0.29176928\n",
      "Iteration 1280, loss = 0.29162701\n",
      "Iteration 1281, loss = 0.29159474\n",
      "Iteration 1282, loss = 0.29148958\n",
      "Iteration 1283, loss = 0.29137406\n",
      "Iteration 1284, loss = 0.29130698\n",
      "Iteration 1285, loss = 0.29123380\n",
      "Iteration 1286, loss = 0.29112326\n",
      "Iteration 1287, loss = 0.29094874\n",
      "Iteration 1288, loss = 0.29096212\n",
      "Iteration 1289, loss = 0.29076558\n",
      "Iteration 1290, loss = 0.29068954\n",
      "Iteration 1291, loss = 0.29067459\n",
      "Iteration 1292, loss = 0.29045111\n",
      "Iteration 1293, loss = 0.29042524\n",
      "Iteration 1294, loss = 0.29030664\n",
      "Iteration 1295, loss = 0.29031822\n",
      "Iteration 1296, loss = 0.29019784\n",
      "Iteration 1297, loss = 0.29008165\n",
      "Iteration 1298, loss = 0.29001277\n",
      "Iteration 1299, loss = 0.28979316\n",
      "Iteration 1300, loss = 0.28968930\n",
      "Iteration 1301, loss = 0.28963298\n",
      "Iteration 1302, loss = 0.28959040\n",
      "Iteration 1303, loss = 0.28942875\n",
      "Iteration 1304, loss = 0.28934856\n",
      "Iteration 1305, loss = 0.28928651\n",
      "Iteration 1306, loss = 0.28921786\n",
      "Iteration 1307, loss = 0.28911069\n",
      "Iteration 1308, loss = 0.28902609\n",
      "Iteration 1309, loss = 0.28892251\n",
      "Iteration 1310, loss = 0.28880157\n",
      "Iteration 1311, loss = 0.28867702\n",
      "Iteration 1312, loss = 0.28861558\n",
      "Iteration 1313, loss = 0.28858762\n",
      "Iteration 1314, loss = 0.28842286\n",
      "Iteration 1315, loss = 0.28836480\n",
      "Iteration 1316, loss = 0.28826935\n",
      "Iteration 1317, loss = 0.28816637\n",
      "Iteration 1318, loss = 0.28809409\n",
      "Iteration 1319, loss = 0.28800568\n",
      "Iteration 1320, loss = 0.28795732\n",
      "Iteration 1321, loss = 0.28796945\n",
      "Iteration 1322, loss = 0.28779988\n",
      "Iteration 1323, loss = 0.28757864\n",
      "Iteration 1324, loss = 0.28756318\n",
      "Iteration 1325, loss = 0.28750889\n",
      "Iteration 1326, loss = 0.28731052\n",
      "Iteration 1327, loss = 0.28719041\n",
      "Iteration 1328, loss = 0.28723405\n",
      "Iteration 1329, loss = 0.28702627\n",
      "Iteration 1330, loss = 0.28695692\n",
      "Iteration 1331, loss = 0.28676807\n",
      "Iteration 1332, loss = 0.28678469\n",
      "Iteration 1333, loss = 0.28662048\n",
      "Iteration 1334, loss = 0.28655855\n",
      "Iteration 1335, loss = 0.28651564\n",
      "Iteration 1336, loss = 0.28640758\n",
      "Iteration 1337, loss = 0.28631367\n",
      "Iteration 1338, loss = 0.28624870\n",
      "Iteration 1339, loss = 0.28604804\n",
      "Iteration 1340, loss = 0.28605932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1341, loss = 0.28603948\n",
      "Iteration 1342, loss = 0.28593006\n",
      "Iteration 1343, loss = 0.28584256\n",
      "Iteration 1344, loss = 0.28584644\n",
      "Iteration 1345, loss = 0.28563453\n",
      "Iteration 1346, loss = 0.28575964\n",
      "Iteration 1347, loss = 0.28539319\n",
      "Iteration 1348, loss = 0.28526988\n",
      "Iteration 1349, loss = 0.28528149\n",
      "Iteration 1350, loss = 0.28517777\n",
      "Iteration 1351, loss = 0.28505206\n",
      "Iteration 1352, loss = 0.28487864\n",
      "Iteration 1353, loss = 0.28487931\n",
      "Iteration 1354, loss = 0.28488939\n",
      "Iteration 1355, loss = 0.28483027\n",
      "Iteration 1356, loss = 0.28472316\n",
      "Iteration 1357, loss = 0.28466296\n",
      "Iteration 1358, loss = 0.28449352\n",
      "Iteration 1359, loss = 0.28454755\n",
      "Iteration 1360, loss = 0.28444159\n",
      "Iteration 1361, loss = 0.28423893\n",
      "Iteration 1362, loss = 0.28415472\n",
      "Iteration 1363, loss = 0.28415635\n",
      "Iteration 1364, loss = 0.28423612\n",
      "Iteration 1365, loss = 0.28389918\n",
      "Iteration 1366, loss = 0.28385414\n",
      "Iteration 1367, loss = 0.28377818\n",
      "Iteration 1368, loss = 0.28373908\n",
      "Iteration 1369, loss = 0.28359224\n",
      "Iteration 1370, loss = 0.28355619\n",
      "Iteration 1371, loss = 0.28348182\n",
      "Iteration 1372, loss = 0.28342840\n",
      "Iteration 1373, loss = 0.28335802\n",
      "Iteration 1374, loss = 0.28326238\n",
      "Iteration 1375, loss = 0.28325695\n",
      "Iteration 1376, loss = 0.28317127\n",
      "Iteration 1377, loss = 0.28319927\n",
      "Iteration 1378, loss = 0.28302351\n",
      "Iteration 1379, loss = 0.28296472\n",
      "Iteration 1380, loss = 0.28308289\n",
      "Iteration 1381, loss = 0.28280870\n",
      "Iteration 1382, loss = 0.28272750\n",
      "Iteration 1383, loss = 0.28274931\n",
      "Iteration 1384, loss = 0.28257541\n",
      "Iteration 1385, loss = 0.28267394\n",
      "Iteration 1386, loss = 0.28245433\n",
      "Iteration 1387, loss = 0.28242185\n",
      "Iteration 1388, loss = 0.28241164\n",
      "Iteration 1389, loss = 0.28240265\n",
      "Iteration 1390, loss = 0.28214330\n",
      "Iteration 1391, loss = 0.28220847\n",
      "Iteration 1392, loss = 0.28195049\n",
      "Iteration 1393, loss = 0.28215607\n",
      "Iteration 1394, loss = 0.28194648\n",
      "Iteration 1395, loss = 0.28193484\n",
      "Iteration 1396, loss = 0.28175202\n",
      "Iteration 1397, loss = 0.28169483\n",
      "Iteration 1398, loss = 0.28170068\n",
      "Iteration 1399, loss = 0.28158952\n",
      "Iteration 1400, loss = 0.28154771\n",
      "Iteration 1401, loss = 0.28139557\n",
      "Iteration 1402, loss = 0.28134524\n",
      "Iteration 1403, loss = 0.28141586\n",
      "Iteration 1404, loss = 0.28131900\n",
      "Iteration 1405, loss = 0.28117311\n",
      "Iteration 1406, loss = 0.28127711\n",
      "Iteration 1407, loss = 0.28106901\n",
      "Iteration 1408, loss = 0.28116508\n",
      "Iteration 1409, loss = 0.28115955\n",
      "Iteration 1410, loss = 0.28088103\n",
      "Iteration 1411, loss = 0.28080622\n",
      "Iteration 1412, loss = 0.28088035\n",
      "Iteration 1413, loss = 0.28077596\n",
      "Iteration 1414, loss = 0.28064189\n",
      "Iteration 1415, loss = 0.28080870\n",
      "Iteration 1416, loss = 0.28064554\n",
      "Iteration 1417, loss = 0.28052660\n",
      "Iteration 1418, loss = 0.28041358\n",
      "Iteration 1419, loss = 0.28041312\n",
      "Iteration 1420, loss = 0.28035946\n",
      "Iteration 1421, loss = 0.28016255\n",
      "Iteration 1422, loss = 0.28005568\n",
      "Iteration 1423, loss = 0.28012320\n",
      "Iteration 1424, loss = 0.28011144\n",
      "Iteration 1425, loss = 0.27992158\n",
      "Iteration 1426, loss = 0.27983292\n",
      "Iteration 1427, loss = 0.27974886\n",
      "Iteration 1428, loss = 0.27962717\n",
      "Iteration 1429, loss = 0.27961709\n",
      "Iteration 1430, loss = 0.27952041\n",
      "Iteration 1431, loss = 0.27954205\n",
      "Iteration 1432, loss = 0.27955276\n",
      "Iteration 1433, loss = 0.27941380\n",
      "Iteration 1434, loss = 0.27920149\n",
      "Iteration 1435, loss = 0.27914729\n",
      "Iteration 1436, loss = 0.27917742\n",
      "Iteration 1437, loss = 0.27893841\n",
      "Iteration 1438, loss = 0.27888875\n",
      "Iteration 1439, loss = 0.27881475\n",
      "Iteration 1440, loss = 0.27891733\n",
      "Iteration 1441, loss = 0.27869738\n",
      "Iteration 1442, loss = 0.27858227\n",
      "Iteration 1443, loss = 0.27853206\n",
      "Iteration 1444, loss = 0.27850591\n",
      "Iteration 1445, loss = 0.27841836\n",
      "Iteration 1446, loss = 0.27833592\n",
      "Iteration 1447, loss = 0.27851578\n",
      "Iteration 1448, loss = 0.27831679\n",
      "Iteration 1449, loss = 0.27818047\n",
      "Iteration 1450, loss = 0.27804131\n",
      "Iteration 1451, loss = 0.27809727\n",
      "Iteration 1452, loss = 0.27792414\n",
      "Iteration 1453, loss = 0.27785312\n",
      "Iteration 1454, loss = 0.27778809\n",
      "Iteration 1455, loss = 0.27772077\n",
      "Iteration 1456, loss = 0.27767463\n",
      "Iteration 1457, loss = 0.27751967\n",
      "Iteration 1458, loss = 0.27752628\n",
      "Iteration 1459, loss = 0.27739299\n",
      "Iteration 1460, loss = 0.27740281\n",
      "Iteration 1461, loss = 0.27717755\n",
      "Iteration 1462, loss = 0.27707127\n",
      "Iteration 1463, loss = 0.27720746\n",
      "Iteration 1464, loss = 0.27710252\n",
      "Iteration 1465, loss = 0.27697113\n",
      "Iteration 1466, loss = 0.27694813\n",
      "Iteration 1467, loss = 0.27690479\n",
      "Iteration 1468, loss = 0.27675454\n",
      "Iteration 1469, loss = 0.27662015\n",
      "Iteration 1470, loss = 0.27657052\n",
      "Iteration 1471, loss = 0.27645765\n",
      "Iteration 1472, loss = 0.27645703\n",
      "Iteration 1473, loss = 0.27627601\n",
      "Iteration 1474, loss = 0.27621125\n",
      "Iteration 1475, loss = 0.27613263\n",
      "Iteration 1476, loss = 0.27602958\n",
      "Iteration 1477, loss = 0.27597907\n",
      "Iteration 1478, loss = 0.27600294\n",
      "Iteration 1479, loss = 0.27579104\n",
      "Iteration 1480, loss = 0.27575048\n",
      "Iteration 1481, loss = 0.27564772\n",
      "Iteration 1482, loss = 0.27557726\n",
      "Iteration 1483, loss = 0.27546628\n",
      "Iteration 1484, loss = 0.27544173\n",
      "Iteration 1485, loss = 0.27541591\n",
      "Iteration 1486, loss = 0.27524723\n",
      "Iteration 1487, loss = 0.27518519\n",
      "Iteration 1488, loss = 0.27508788\n",
      "Iteration 1489, loss = 0.27509705\n",
      "Iteration 1490, loss = 0.27498139\n",
      "Iteration 1491, loss = 0.27488328\n",
      "Iteration 1492, loss = 0.27481993\n",
      "Iteration 1493, loss = 0.27469870\n",
      "Iteration 1494, loss = 0.27455590\n",
      "Iteration 1495, loss = 0.27451918\n",
      "Iteration 1496, loss = 0.27443635\n",
      "Iteration 1497, loss = 0.27436560\n",
      "Iteration 1498, loss = 0.27441387\n",
      "Iteration 1499, loss = 0.27429818\n",
      "Iteration 1500, loss = 0.27418882\n",
      "Iteration 1501, loss = 0.27415190\n",
      "Iteration 1502, loss = 0.27400657\n",
      "Iteration 1503, loss = 0.27379055\n",
      "Iteration 1504, loss = 0.27381951\n",
      "Iteration 1505, loss = 0.27376642\n",
      "Iteration 1506, loss = 0.27380598\n",
      "Iteration 1507, loss = 0.27350267\n",
      "Iteration 1508, loss = 0.27352947\n",
      "Iteration 1509, loss = 0.27354831\n",
      "Iteration 1510, loss = 0.27342355\n",
      "Iteration 1511, loss = 0.27327325\n",
      "Iteration 1512, loss = 0.27317049\n",
      "Iteration 1513, loss = 0.27330631\n",
      "Iteration 1514, loss = 0.27319989\n",
      "Iteration 1515, loss = 0.27303345\n",
      "Iteration 1516, loss = 0.27289223\n",
      "Iteration 1517, loss = 0.27292308\n",
      "Iteration 1518, loss = 0.27271001\n",
      "Iteration 1519, loss = 0.27269324\n",
      "Iteration 1520, loss = 0.27251067\n",
      "Iteration 1521, loss = 0.27254363\n",
      "Iteration 1522, loss = 0.27271841\n",
      "Iteration 1523, loss = 0.27229398\n",
      "Iteration 1524, loss = 0.27250868\n",
      "Iteration 1525, loss = 0.27232827\n",
      "Iteration 1526, loss = 0.27222265\n",
      "Iteration 1527, loss = 0.27212962\n",
      "Iteration 1528, loss = 0.27206751\n",
      "Iteration 1529, loss = 0.27200024\n",
      "Iteration 1530, loss = 0.27194640\n",
      "Iteration 1531, loss = 0.27188180\n",
      "Iteration 1532, loss = 0.27182950\n",
      "Iteration 1533, loss = 0.27167189\n",
      "Iteration 1534, loss = 0.27156884\n",
      "Iteration 1535, loss = 0.27139907\n",
      "Iteration 1536, loss = 0.27144384\n",
      "Iteration 1537, loss = 0.27129908\n",
      "Iteration 1538, loss = 0.27117697\n",
      "Iteration 1539, loss = 0.27116888\n",
      "Iteration 1540, loss = 0.27108641\n",
      "Iteration 1541, loss = 0.27095019\n",
      "Iteration 1542, loss = 0.27087371\n",
      "Iteration 1543, loss = 0.27102920\n",
      "Iteration 1544, loss = 0.27092228\n",
      "Iteration 1545, loss = 0.27078411\n",
      "Iteration 1546, loss = 0.27093988\n",
      "Iteration 1547, loss = 0.27065364\n",
      "Iteration 1548, loss = 0.27057223\n",
      "Iteration 1549, loss = 0.27048220\n",
      "Iteration 1550, loss = 0.27043870\n",
      "Iteration 1551, loss = 0.27034245\n",
      "Iteration 1552, loss = 0.27022165\n",
      "Iteration 1553, loss = 0.27030195\n",
      "Iteration 1554, loss = 0.27013352\n",
      "Iteration 1555, loss = 0.27022725\n",
      "Iteration 1556, loss = 0.27030615\n",
      "Iteration 1557, loss = 0.26992965\n",
      "Iteration 1558, loss = 0.26983670\n",
      "Iteration 1559, loss = 0.26974818\n",
      "Iteration 1560, loss = 0.26966350\n",
      "Iteration 1561, loss = 0.26958521\n",
      "Iteration 1562, loss = 0.26946126\n",
      "Iteration 1563, loss = 0.26942482\n",
      "Iteration 1564, loss = 0.26947349\n",
      "Iteration 1565, loss = 0.26940020\n",
      "Iteration 1566, loss = 0.26938269\n",
      "Iteration 1567, loss = 0.26923104\n",
      "Iteration 1568, loss = 0.26918930\n",
      "Iteration 1569, loss = 0.26910140\n",
      "Iteration 1570, loss = 0.26907151\n",
      "Iteration 1571, loss = 0.26902222\n",
      "Iteration 1572, loss = 0.26893996\n",
      "Iteration 1573, loss = 0.26905705\n",
      "Iteration 1574, loss = 0.26882656\n",
      "Iteration 1575, loss = 0.26866482\n",
      "Iteration 1576, loss = 0.26868749\n",
      "Iteration 1577, loss = 0.26858377\n",
      "Iteration 1578, loss = 0.26846835\n",
      "Iteration 1579, loss = 0.26832940\n",
      "Iteration 1580, loss = 0.26825200\n",
      "Iteration 1581, loss = 0.26841438\n",
      "Iteration 1582, loss = 0.26812141\n",
      "Iteration 1583, loss = 0.26794363\n",
      "Iteration 1584, loss = 0.26784712\n",
      "Iteration 1585, loss = 0.26789068\n",
      "Iteration 1586, loss = 0.26773259\n",
      "Iteration 1587, loss = 0.26773799\n",
      "Iteration 1588, loss = 0.26747123\n",
      "Iteration 1589, loss = 0.26729473\n",
      "Iteration 1590, loss = 0.26754959\n",
      "Iteration 1591, loss = 0.26747254\n",
      "Iteration 1592, loss = 0.26724612\n",
      "Iteration 1593, loss = 0.26716317\n",
      "Iteration 1594, loss = 0.26702697\n",
      "Iteration 1595, loss = 0.26689093\n",
      "Iteration 1596, loss = 0.26677174\n",
      "Iteration 1597, loss = 0.26670010\n",
      "Iteration 1598, loss = 0.26664266\n",
      "Iteration 1599, loss = 0.26647283\n",
      "Iteration 1600, loss = 0.26654623\n",
      "Iteration 1601, loss = 0.26630778\n",
      "Iteration 1602, loss = 0.26646901\n",
      "Iteration 1603, loss = 0.26634205\n",
      "Iteration 1604, loss = 0.26630794\n",
      "Iteration 1605, loss = 0.26612362\n",
      "Iteration 1606, loss = 0.26606091\n",
      "Iteration 1607, loss = 0.26599297\n",
      "Iteration 1608, loss = 0.26594628\n",
      "Iteration 1609, loss = 0.26588121\n",
      "Iteration 1610, loss = 0.26583081\n",
      "Iteration 1611, loss = 0.26563510\n",
      "Iteration 1612, loss = 0.26565981\n",
      "Iteration 1613, loss = 0.26558404\n",
      "Iteration 1614, loss = 0.26551852\n",
      "Iteration 1615, loss = 0.26559197\n",
      "Iteration 1616, loss = 0.26543775\n",
      "Iteration 1617, loss = 0.26541481\n",
      "Iteration 1618, loss = 0.26534984\n",
      "Iteration 1619, loss = 0.26526099\n",
      "Iteration 1620, loss = 0.26514604\n",
      "Iteration 1621, loss = 0.26501555\n",
      "Iteration 1622, loss = 0.26498272\n",
      "Iteration 1623, loss = 0.26481920\n",
      "Iteration 1624, loss = 0.26463486\n",
      "Iteration 1625, loss = 0.26464510\n",
      "Iteration 1626, loss = 0.26459584\n",
      "Iteration 1627, loss = 0.26455483\n",
      "Iteration 1628, loss = 0.26459359\n",
      "Iteration 1629, loss = 0.26439355\n",
      "Iteration 1630, loss = 0.26439817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1631, loss = 0.26444277\n",
      "Iteration 1632, loss = 0.26431337\n",
      "Iteration 1633, loss = 0.26428992\n",
      "Iteration 1634, loss = 0.26413997\n",
      "Iteration 1635, loss = 0.26406168\n",
      "Iteration 1636, loss = 0.26395218\n",
      "Iteration 1637, loss = 0.26396208\n",
      "Iteration 1638, loss = 0.26386394\n",
      "Iteration 1639, loss = 0.26390672\n",
      "Iteration 1640, loss = 0.26374586\n",
      "Iteration 1641, loss = 0.26360208\n",
      "Iteration 1642, loss = 0.26357019\n",
      "Iteration 1643, loss = 0.26346316\n",
      "Iteration 1644, loss = 0.26348393\n",
      "Iteration 1645, loss = 0.26346576\n",
      "Iteration 1646, loss = 0.26339648\n",
      "Iteration 1647, loss = 0.26345306\n",
      "Iteration 1648, loss = 0.26320288\n",
      "Iteration 1649, loss = 0.26316079\n",
      "Iteration 1650, loss = 0.26307134\n",
      "Iteration 1651, loss = 0.26308263\n",
      "Iteration 1652, loss = 0.26309016\n",
      "Iteration 1653, loss = 0.26299094\n",
      "Iteration 1654, loss = 0.26292496\n",
      "Iteration 1655, loss = 0.26286716\n",
      "Iteration 1656, loss = 0.26279739\n",
      "Iteration 1657, loss = 0.26272486\n",
      "Iteration 1658, loss = 0.26272967\n",
      "Iteration 1659, loss = 0.26259499\n",
      "Iteration 1660, loss = 0.26253749\n",
      "Iteration 1661, loss = 0.26237210\n",
      "Iteration 1662, loss = 0.26252327\n",
      "Iteration 1663, loss = 0.26240204\n",
      "Iteration 1664, loss = 0.26233346\n",
      "Iteration 1665, loss = 0.26228583\n",
      "Iteration 1666, loss = 0.26215936\n",
      "Iteration 1667, loss = 0.26204340\n",
      "Iteration 1668, loss = 0.26200691\n",
      "Iteration 1669, loss = 0.26206576\n",
      "Iteration 1670, loss = 0.26206731\n",
      "Iteration 1671, loss = 0.26185355\n",
      "Iteration 1672, loss = 0.26181034\n",
      "Iteration 1673, loss = 0.26185290\n",
      "Iteration 1674, loss = 0.26171603\n",
      "Iteration 1675, loss = 0.26169126\n",
      "Iteration 1676, loss = 0.26149593\n",
      "Iteration 1677, loss = 0.26138068\n",
      "Iteration 1678, loss = 0.26157268\n",
      "Iteration 1679, loss = 0.26139582\n",
      "Iteration 1680, loss = 0.26133575\n",
      "Iteration 1681, loss = 0.26131653\n",
      "Iteration 1682, loss = 0.26123815\n",
      "Iteration 1683, loss = 0.26121486\n",
      "Iteration 1684, loss = 0.26110474\n",
      "Iteration 1685, loss = 0.26113021\n",
      "Iteration 1686, loss = 0.26099919\n",
      "Iteration 1687, loss = 0.26089896\n",
      "Iteration 1688, loss = 0.26078033\n",
      "Iteration 1689, loss = 0.26097992\n",
      "Iteration 1690, loss = 0.26073758\n",
      "Iteration 1691, loss = 0.26074532\n",
      "Iteration 1692, loss = 0.26059931\n",
      "Iteration 1693, loss = 0.26053599\n",
      "Iteration 1694, loss = 0.26051348\n",
      "Iteration 1695, loss = 0.26039536\n",
      "Iteration 1696, loss = 0.26028355\n",
      "Iteration 1697, loss = 0.26018447\n",
      "Iteration 1698, loss = 0.26021424\n",
      "Iteration 1699, loss = 0.26012105\n",
      "Iteration 1700, loss = 0.26007968\n",
      "Iteration 1701, loss = 0.26002889\n",
      "Iteration 1702, loss = 0.25986853\n",
      "Iteration 1703, loss = 0.26001427\n",
      "Iteration 1704, loss = 0.25985821\n",
      "Iteration 1705, loss = 0.25980809\n",
      "Iteration 1706, loss = 0.25959187\n",
      "Iteration 1707, loss = 0.25956397\n",
      "Iteration 1708, loss = 0.25968215\n",
      "Iteration 1709, loss = 0.25945948\n",
      "Iteration 1710, loss = 0.25951436\n",
      "Iteration 1711, loss = 0.25939800\n",
      "Iteration 1712, loss = 0.25927501\n",
      "Iteration 1713, loss = 0.25926906\n",
      "Iteration 1714, loss = 0.25918047\n",
      "Iteration 1715, loss = 0.25920819\n",
      "Iteration 1716, loss = 0.25902888\n",
      "Iteration 1717, loss = 0.25896919\n",
      "Iteration 1718, loss = 0.25903002\n",
      "Iteration 1719, loss = 0.25881106\n",
      "Iteration 1720, loss = 0.25869064\n",
      "Iteration 1721, loss = 0.25859787\n",
      "Iteration 1722, loss = 0.25856967\n",
      "Iteration 1723, loss = 0.25855579\n",
      "Iteration 1724, loss = 0.25850748\n",
      "Iteration 1725, loss = 0.25856455\n",
      "Iteration 1726, loss = 0.25830338\n",
      "Iteration 1727, loss = 0.25818584\n",
      "Iteration 1728, loss = 0.25814745\n",
      "Iteration 1729, loss = 0.25832980\n",
      "Iteration 1730, loss = 0.25826137\n",
      "Iteration 1731, loss = 0.25816273\n",
      "Iteration 1732, loss = 0.25802842\n",
      "Iteration 1733, loss = 0.25793920\n",
      "Iteration 1734, loss = 0.25788870\n",
      "Iteration 1735, loss = 0.25781656\n",
      "Iteration 1736, loss = 0.25787928\n",
      "Iteration 1737, loss = 0.25792299\n",
      "Iteration 1738, loss = 0.25782012\n",
      "Iteration 1739, loss = 0.25773003\n",
      "Iteration 1740, loss = 0.25764304\n",
      "Iteration 1741, loss = 0.25755434\n",
      "Iteration 1742, loss = 0.25757609\n",
      "Iteration 1743, loss = 0.25743523\n",
      "Iteration 1744, loss = 0.25742410\n",
      "Iteration 1745, loss = 0.25738446\n",
      "Iteration 1746, loss = 0.25714855\n",
      "Iteration 1747, loss = 0.25719715\n",
      "Iteration 1748, loss = 0.25713810\n",
      "Iteration 1749, loss = 0.25704597\n",
      "Iteration 1750, loss = 0.25708811\n",
      "Iteration 1751, loss = 0.25706221\n",
      "Iteration 1752, loss = 0.25701701\n",
      "Iteration 1753, loss = 0.25677447\n",
      "Iteration 1754, loss = 0.25684447\n",
      "Iteration 1755, loss = 0.25673117\n",
      "Iteration 1756, loss = 0.25668411\n",
      "Iteration 1757, loss = 0.25656189\n",
      "Iteration 1758, loss = 0.25662652\n",
      "Iteration 1759, loss = 0.25649985\n",
      "Iteration 1760, loss = 0.25669172\n",
      "Iteration 1761, loss = 0.25648410\n",
      "Iteration 1762, loss = 0.25635779\n",
      "Iteration 1763, loss = 0.25627627\n",
      "Iteration 1764, loss = 0.25658298\n",
      "Iteration 1765, loss = 0.25631827\n",
      "Iteration 1766, loss = 0.25634751\n",
      "Iteration 1767, loss = 0.25624062\n",
      "Iteration 1768, loss = 0.25607824\n",
      "Iteration 1769, loss = 0.25608537\n",
      "Iteration 1770, loss = 0.25608204\n",
      "Iteration 1771, loss = 0.25585753\n",
      "Iteration 1772, loss = 0.25589022\n",
      "Iteration 1773, loss = 0.25586789\n",
      "Iteration 1774, loss = 0.25582456\n",
      "Iteration 1775, loss = 0.25578930\n",
      "Iteration 1776, loss = 0.25577000\n",
      "Iteration 1777, loss = 0.25564728\n",
      "Iteration 1778, loss = 0.25565114\n",
      "Iteration 1779, loss = 0.25554806\n",
      "Iteration 1780, loss = 0.25553290\n",
      "Iteration 1781, loss = 0.25545377\n",
      "Iteration 1782, loss = 0.25536936\n",
      "Iteration 1783, loss = 0.25540654\n",
      "Iteration 1784, loss = 0.25536881\n",
      "Iteration 1785, loss = 0.25542247\n",
      "Iteration 1786, loss = 0.25541044\n",
      "Iteration 1787, loss = 0.25537075\n",
      "Iteration 1788, loss = 0.25521564\n",
      "Iteration 1789, loss = 0.25525440\n",
      "Iteration 1790, loss = 0.25525823\n",
      "Iteration 1791, loss = 0.25519150\n",
      "Iteration 1792, loss = 0.25498996\n",
      "Iteration 1793, loss = 0.25493972\n",
      "Iteration 1794, loss = 0.25481298\n",
      "Iteration 1795, loss = 0.25484141\n",
      "Iteration 1796, loss = 0.25490089\n",
      "Iteration 1797, loss = 0.25480427\n",
      "Iteration 1798, loss = 0.25465305\n",
      "Iteration 1799, loss = 0.25478688\n",
      "Iteration 1800, loss = 0.25458289\n",
      "Iteration 1801, loss = 0.25450146\n",
      "Iteration 1802, loss = 0.25445531\n",
      "Iteration 1803, loss = 0.25447382\n",
      "Iteration 1804, loss = 0.25448301\n",
      "Iteration 1805, loss = 0.25430944\n",
      "Iteration 1806, loss = 0.25432051\n",
      "Iteration 1807, loss = 0.25429936\n",
      "Iteration 1808, loss = 0.25430060\n",
      "Iteration 1809, loss = 0.25426864\n",
      "Iteration 1810, loss = 0.25421452\n",
      "Iteration 1811, loss = 0.25421796\n",
      "Iteration 1812, loss = 0.25404435\n",
      "Iteration 1813, loss = 0.25401427\n",
      "Iteration 1814, loss = 0.25402460\n",
      "Iteration 1815, loss = 0.25395768\n",
      "Iteration 1816, loss = 0.25393248\n",
      "Iteration 1817, loss = 0.25390002\n",
      "Iteration 1818, loss = 0.25385740\n",
      "Iteration 1819, loss = 0.25378886\n",
      "Iteration 1820, loss = 0.25406457\n",
      "Iteration 1821, loss = 0.25402347\n",
      "Iteration 1822, loss = 0.25361476\n",
      "Iteration 1823, loss = 0.25364476\n",
      "Iteration 1824, loss = 0.25360545\n",
      "Iteration 1825, loss = 0.25362163\n",
      "Iteration 1826, loss = 0.25353822\n",
      "Iteration 1827, loss = 0.25337519\n",
      "Iteration 1828, loss = 0.25351621\n",
      "Iteration 1829, loss = 0.25351052\n",
      "Iteration 1830, loss = 0.25339611\n",
      "Iteration 1831, loss = 0.25331415\n",
      "Iteration 1832, loss = 0.25320040\n",
      "Iteration 1833, loss = 0.25320874\n",
      "Iteration 1834, loss = 0.25312084\n",
      "Iteration 1835, loss = 0.25340533\n",
      "Iteration 1836, loss = 0.25316339\n",
      "Iteration 1837, loss = 0.25304368\n",
      "Iteration 1838, loss = 0.25304707\n",
      "Iteration 1839, loss = 0.25303473\n",
      "Iteration 1840, loss = 0.25289292\n",
      "Iteration 1841, loss = 0.25283003\n",
      "Iteration 1842, loss = 0.25281490\n",
      "Iteration 1843, loss = 0.25272971\n",
      "Iteration 1844, loss = 0.25279096\n",
      "Iteration 1845, loss = 0.25275180\n",
      "Iteration 1846, loss = 0.25282169\n",
      "Iteration 1847, loss = 0.25255694\n",
      "Iteration 1848, loss = 0.25256555\n",
      "Iteration 1849, loss = 0.25253222\n",
      "Iteration 1850, loss = 0.25234584\n",
      "Iteration 1851, loss = 0.25232325\n",
      "Iteration 1852, loss = 0.25224987\n",
      "Iteration 1853, loss = 0.25235411\n",
      "Iteration 1854, loss = 0.25228291\n",
      "Iteration 1855, loss = 0.25229194\n",
      "Iteration 1856, loss = 0.25219529\n",
      "Iteration 1857, loss = 0.25217122\n",
      "Iteration 1858, loss = 0.25216114\n",
      "Iteration 1859, loss = 0.25212752\n",
      "Iteration 1860, loss = 0.25199609\n",
      "Iteration 1861, loss = 0.25207591\n",
      "Iteration 1862, loss = 0.25206079\n",
      "Iteration 1863, loss = 0.25185740\n",
      "Iteration 1864, loss = 0.25181011\n",
      "Iteration 1865, loss = 0.25185589\n",
      "Iteration 1866, loss = 0.25188952\n",
      "Iteration 1867, loss = 0.25176323\n",
      "Iteration 1868, loss = 0.25162129\n",
      "Iteration 1869, loss = 0.25162786\n",
      "Iteration 1870, loss = 0.25171956\n",
      "Iteration 1871, loss = 0.25186776\n",
      "Iteration 1872, loss = 0.25144973\n",
      "Iteration 1873, loss = 0.25141055\n",
      "Iteration 1874, loss = 0.25146315\n",
      "Iteration 1875, loss = 0.25117415\n",
      "Iteration 1876, loss = 0.25118160\n",
      "Iteration 1877, loss = 0.25127057\n",
      "Iteration 1878, loss = 0.25123787\n",
      "Iteration 1879, loss = 0.25117072\n",
      "Iteration 1880, loss = 0.25125104\n",
      "Iteration 1881, loss = 0.25105985\n",
      "Iteration 1882, loss = 0.25096910\n",
      "Iteration 1883, loss = 0.25095493\n",
      "Iteration 1884, loss = 0.25101698\n",
      "Iteration 1885, loss = 0.25093541\n",
      "Iteration 1886, loss = 0.25093427\n",
      "Iteration 1887, loss = 0.25107287\n",
      "Iteration 1888, loss = 0.25082442\n",
      "Iteration 1889, loss = 0.25072767\n",
      "Iteration 1890, loss = 0.25065573\n",
      "Iteration 1891, loss = 0.25096991\n",
      "Iteration 1892, loss = 0.25069146\n",
      "Iteration 1893, loss = 0.25056966\n",
      "Iteration 1894, loss = 0.25045334\n",
      "Iteration 1895, loss = 0.25034421\n",
      "Iteration 1896, loss = 0.25044859\n",
      "Iteration 1897, loss = 0.25040740\n",
      "Iteration 1898, loss = 0.25051279\n",
      "Iteration 1899, loss = 0.25035647\n",
      "Iteration 1900, loss = 0.25018539\n",
      "Iteration 1901, loss = 0.25017951\n",
      "Iteration 1902, loss = 0.25010332\n",
      "Iteration 1903, loss = 0.25013617\n",
      "Iteration 1904, loss = 0.25009829\n",
      "Iteration 1905, loss = 0.25025669\n",
      "Iteration 1906, loss = 0.25003176\n",
      "Iteration 1907, loss = 0.24998066\n",
      "Iteration 1908, loss = 0.25010215\n",
      "Iteration 1909, loss = 0.24997679\n",
      "Iteration 1910, loss = 0.24994813\n",
      "Iteration 1911, loss = 0.24982766\n",
      "Iteration 1912, loss = 0.24975974\n",
      "Iteration 1913, loss = 0.24974304\n",
      "Iteration 1914, loss = 0.24968750\n",
      "Iteration 1915, loss = 0.24958510\n",
      "Iteration 1916, loss = 0.24973868\n",
      "Iteration 1917, loss = 0.24956438\n",
      "Iteration 1918, loss = 0.24950614\n",
      "Iteration 1919, loss = 0.24942297\n",
      "Iteration 1920, loss = 0.24938864\n",
      "Iteration 1921, loss = 0.24965156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1922, loss = 0.24945348\n",
      "Iteration 1923, loss = 0.24924353\n",
      "Iteration 1924, loss = 0.24931121\n",
      "Iteration 1925, loss = 0.24921095\n",
      "Iteration 1926, loss = 0.24917535\n",
      "Iteration 1927, loss = 0.24912403\n",
      "Iteration 1928, loss = 0.24917207\n",
      "Iteration 1929, loss = 0.24915154\n",
      "Iteration 1930, loss = 0.24904257\n",
      "Iteration 1931, loss = 0.24908571\n",
      "Iteration 1932, loss = 0.24899427\n",
      "Iteration 1933, loss = 0.24903130\n",
      "Iteration 1934, loss = 0.24897207\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 10), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=100000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier  \n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,10), max_iter=100000, verbose=2)  \n",
    "mlp.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7265625\n",
      "[[136  31]\n",
      " [ 39  50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.81      0.80       167\n",
      "         1.0       0.62      0.56      0.59        89\n",
      "\n",
      "    accuracy                           0.73       256\n",
      "   macro avg       0.70      0.69      0.69       256\n",
      "weighted avg       0.72      0.73      0.72       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test)  \n",
    "\n",
    "\n",
    "print(\"Accuracy\", metrics.accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(mlp.loss_curve_)\n",
    "plt.title(\"NN Loss Curve\")\n",
    "plt.xlabel(\"number of steps\")\n",
    "plt.ylabel(\"loss function\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.9007226 ,  0.30795366, -0.76309511,  0.20321883,  0.87117394,\n",
       "       -0.64695102, -0.70394324,  0.55612998,  0.51210861,  0.90669627])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.intercepts_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.72178784e-01,  6.47381432e-01, -7.58956652e-01,\n",
       "         1.66538432e-01,  1.00832380e+00, -6.28674768e-02,\n",
       "         3.25364850e-01, -1.17307812e+00, -2.42544938e-01,\n",
       "        -3.03202883e-01],\n",
       "       [-3.15150829e-01,  4.34672431e-01, -3.01790987e-01,\n",
       "        -6.85679789e-01, -3.85988248e-01,  1.15822701e+00,\n",
       "         2.43380178e-02,  1.29198227e-01,  1.00252825e+00,\n",
       "        -4.59433264e-01],\n",
       "       [-2.75385580e-01,  1.97040173e-01, -3.95655826e-02,\n",
       "         4.27365358e-01, -1.84340272e-01, -3.05577357e-01,\n",
       "         5.80413623e-01,  2.57716059e-01, -5.67445287e-01,\n",
       "         2.22791352e-01],\n",
       "       [-8.40032426e-01,  3.33029648e-01,  8.85873022e-02,\n",
       "        -2.28171756e-01,  5.46105807e-01, -4.66555673e-01,\n",
       "         5.53373918e-01, -6.57790105e-01,  2.03864399e-01,\n",
       "         1.13917989e-01],\n",
       "       [ 1.98426988e-01, -1.85349206e-01,  3.18060789e-01,\n",
       "         4.05586897e-01, -2.82289285e-01,  5.58624059e-01,\n",
       "        -2.82216023e-01,  7.98747364e-01, -7.71239523e-01,\n",
       "         7.82256059e-02],\n",
       "       [-3.22082050e-01, -1.00348339e-01,  8.01930856e-01,\n",
       "        -7.61743558e-02, -2.04365645e-01, -1.18367941e+00,\n",
       "        -6.18688952e-01, -3.58624532e-01,  6.08891020e-01,\n",
       "         2.72381055e-04],\n",
       "       [ 6.78070709e-01,  5.23202557e-01, -1.09507798e+00,\n",
       "        -4.32473133e-01, -3.31907509e-01, -2.97008687e-01,\n",
       "         9.36024571e-01, -1.96262013e-02,  6.45708196e-01,\n",
       "        -7.21197225e-01],\n",
       "       [ 8.13293149e-01, -4.75471565e-01, -3.82893299e-01,\n",
       "         4.81259174e-01,  2.75719369e-01,  3.74666857e-02,\n",
       "        -1.07418855e+00, -1.19294385e+00, -2.17498457e-01,\n",
       "        -1.04064063e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.coefs_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "d:\\apps\\Anaconda3\\envs\\keras-cv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\apps\\Anaconda3\\envs\\keras-cv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\apps\\Anaconda3\\envs\\keras-cv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\apps\\Anaconda3\\envs\\keras-cv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\apps\\Anaconda3\\envs\\keras-cv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\apps\\Anaconda3\\envs\\keras-cv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "# create keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conda install pydot pydotplus\n",
    "import pydot\n",
    "from keras.utils import plot_model\n",
    "import IPython\n",
    "plot_model(model, to_file='model.png',show_shapes=True)\n",
    "IPython.display.Image(\"model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 384 samples, validate on 128 samples\n",
      "Epoch 1/80\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.6902 - acc: 0.6563 - val_loss: 0.6881 - val_acc: 0.6172\n",
      "Epoch 2/80\n",
      "384/384 [==============================] - 0s 221us/step - loss: 0.6784 - acc: 0.6615 - val_loss: 0.6722 - val_acc: 0.6172\n",
      "Epoch 3/80\n",
      "384/384 [==============================] - 0s 217us/step - loss: 0.6425 - acc: 0.6589 - val_loss: 0.6316 - val_acc: 0.6328\n",
      "Epoch 4/80\n",
      "384/384 [==============================] - 0s 218us/step - loss: 0.5813 - acc: 0.7135 - val_loss: 0.5788 - val_acc: 0.7422\n",
      "Epoch 5/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.5272 - acc: 0.7865 - val_loss: 0.5464 - val_acc: 0.7656\n",
      "Epoch 6/80\n",
      "384/384 [==============================] - 0s 221us/step - loss: 0.4965 - acc: 0.7891 - val_loss: 0.5283 - val_acc: 0.7578\n",
      "Epoch 7/80\n",
      "384/384 [==============================] - 0s 218us/step - loss: 0.4795 - acc: 0.7813 - val_loss: 0.5149 - val_acc: 0.7734\n",
      "Epoch 8/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4695 - acc: 0.7812 - val_loss: 0.5016 - val_acc: 0.7656\n",
      "Epoch 9/80\n",
      "384/384 [==============================] - 0s 231us/step - loss: 0.4632 - acc: 0.7839 - val_loss: 0.4978 - val_acc: 0.7734\n",
      "Epoch 10/80\n",
      "384/384 [==============================] - 0s 218us/step - loss: 0.4603 - acc: 0.7786 - val_loss: 0.4916 - val_acc: 0.7812\n",
      "Epoch 11/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4585 - acc: 0.7812 - val_loss: 0.4878 - val_acc: 0.7734\n",
      "Epoch 12/80\n",
      "384/384 [==============================] - 0s 221us/step - loss: 0.4568 - acc: 0.7865 - val_loss: 0.4892 - val_acc: 0.7891\n",
      "Epoch 13/80\n",
      "384/384 [==============================] - 0s 218us/step - loss: 0.4541 - acc: 0.7786 - val_loss: 0.4851 - val_acc: 0.7734\n",
      "Epoch 14/80\n",
      "384/384 [==============================] - 0s 229us/step - loss: 0.4519 - acc: 0.7813 - val_loss: 0.4831 - val_acc: 0.7891\n",
      "Epoch 15/80\n",
      "384/384 [==============================] - 0s 223us/step - loss: 0.4516 - acc: 0.7812 - val_loss: 0.4811 - val_acc: 0.7891\n",
      "Epoch 16/80\n",
      "384/384 [==============================] - 0s 223us/step - loss: 0.4497 - acc: 0.7786 - val_loss: 0.4804 - val_acc: 0.7812\n",
      "Epoch 17/80\n",
      "384/384 [==============================] - 0s 218us/step - loss: 0.4502 - acc: 0.7812 - val_loss: 0.4792 - val_acc: 0.7812\n",
      "Epoch 18/80\n",
      "384/384 [==============================] - 0s 221us/step - loss: 0.4478 - acc: 0.7839 - val_loss: 0.4809 - val_acc: 0.7812\n",
      "Epoch 19/80\n",
      "384/384 [==============================] - 0s 220us/step - loss: 0.4473 - acc: 0.7812 - val_loss: 0.4838 - val_acc: 0.7656\n",
      "Epoch 20/80\n",
      "384/384 [==============================] - 0s 213us/step - loss: 0.4472 - acc: 0.7839 - val_loss: 0.4816 - val_acc: 0.7656\n",
      "Epoch 21/80\n",
      "384/384 [==============================] - 0s 218us/step - loss: 0.4449 - acc: 0.7839 - val_loss: 0.4849 - val_acc: 0.7656\n",
      "Epoch 22/80\n",
      "384/384 [==============================] - 0s 228us/step - loss: 0.4443 - acc: 0.7839 - val_loss: 0.4825 - val_acc: 0.7734\n",
      "Epoch 23/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4441 - acc: 0.7865 - val_loss: 0.4809 - val_acc: 0.7734\n",
      "Epoch 24/80\n",
      "384/384 [==============================] - 0s 218us/step - loss: 0.4434 - acc: 0.7812 - val_loss: 0.4811 - val_acc: 0.7734\n",
      "Epoch 25/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4425 - acc: 0.7812 - val_loss: 0.4820 - val_acc: 0.7734\n",
      "Epoch 26/80\n",
      "384/384 [==============================] - 0s 223us/step - loss: 0.4426 - acc: 0.7812 - val_loss: 0.4837 - val_acc: 0.7734\n",
      "Epoch 27/80\n",
      "384/384 [==============================] - 0s 213us/step - loss: 0.4422 - acc: 0.7812 - val_loss: 0.4870 - val_acc: 0.7656\n",
      "Epoch 28/80\n",
      "384/384 [==============================] - 0s 223us/step - loss: 0.4417 - acc: 0.7839 - val_loss: 0.4838 - val_acc: 0.7734\n",
      "Epoch 29/80\n",
      "384/384 [==============================] - 0s 221us/step - loss: 0.4419 - acc: 0.7865 - val_loss: 0.4828 - val_acc: 0.7734\n",
      "Epoch 30/80\n",
      "384/384 [==============================] - 0s 221us/step - loss: 0.4407 - acc: 0.7865 - val_loss: 0.4847 - val_acc: 0.7656\n",
      "Epoch 31/80\n",
      "384/384 [==============================] - 0s 226us/step - loss: 0.4408 - acc: 0.7865 - val_loss: 0.4867 - val_acc: 0.7656\n",
      "Epoch 32/80\n",
      "384/384 [==============================] - 0s 221us/step - loss: 0.4401 - acc: 0.7839 - val_loss: 0.4840 - val_acc: 0.7734\n",
      "Epoch 33/80\n",
      "384/384 [==============================] - 0s 213us/step - loss: 0.4393 - acc: 0.7865 - val_loss: 0.4865 - val_acc: 0.7656\n",
      "Epoch 34/80\n",
      "384/384 [==============================] - 0s 231us/step - loss: 0.4401 - acc: 0.7839 - val_loss: 0.4831 - val_acc: 0.7734\n",
      "Epoch 35/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4395 - acc: 0.7865 - val_loss: 0.4892 - val_acc: 0.7734\n",
      "Epoch 36/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4383 - acc: 0.7865 - val_loss: 0.4872 - val_acc: 0.7656\n",
      "Epoch 37/80\n",
      "384/384 [==============================] - 0s 218us/step - loss: 0.4381 - acc: 0.7865 - val_loss: 0.4887 - val_acc: 0.7656\n",
      "Epoch 38/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4385 - acc: 0.7865 - val_loss: 0.4852 - val_acc: 0.7656\n",
      "Epoch 39/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4371 - acc: 0.7865 - val_loss: 0.4897 - val_acc: 0.7656\n",
      "Epoch 40/80\n",
      "384/384 [==============================] - 0s 234us/step - loss: 0.4379 - acc: 0.7839 - val_loss: 0.4921 - val_acc: 0.7656\n",
      "Epoch 41/80\n",
      "384/384 [==============================] - 0s 237us/step - loss: 0.4377 - acc: 0.7865 - val_loss: 0.4892 - val_acc: 0.7734\n",
      "Epoch 42/80\n",
      "384/384 [==============================] - 0s 221us/step - loss: 0.4367 - acc: 0.7839 - val_loss: 0.4876 - val_acc: 0.7812\n",
      "Epoch 43/80\n",
      "384/384 [==============================] - 0s 220us/step - loss: 0.4370 - acc: 0.7812 - val_loss: 0.4848 - val_acc: 0.7812\n",
      "Epoch 44/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4363 - acc: 0.7839 - val_loss: 0.4927 - val_acc: 0.7656\n",
      "Epoch 45/80\n",
      "384/384 [==============================] - 0s 217us/step - loss: 0.4361 - acc: 0.7917 - val_loss: 0.4866 - val_acc: 0.7734\n",
      "Epoch 46/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4364 - acc: 0.7865 - val_loss: 0.4883 - val_acc: 0.7734\n",
      "Epoch 47/80\n",
      "384/384 [==============================] - 0s 229us/step - loss: 0.4346 - acc: 0.7917 - val_loss: 0.4902 - val_acc: 0.7656\n",
      "Epoch 48/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4344 - acc: 0.7891 - val_loss: 0.4877 - val_acc: 0.7578\n",
      "Epoch 49/80\n",
      "384/384 [==============================] - 0s 221us/step - loss: 0.4336 - acc: 0.7917 - val_loss: 0.4894 - val_acc: 0.7734\n",
      "Epoch 50/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4338 - acc: 0.7917 - val_loss: 0.4922 - val_acc: 0.7656\n",
      "Epoch 51/80\n",
      "384/384 [==============================] - 0s 239us/step - loss: 0.4334 - acc: 0.7943 - val_loss: 0.4910 - val_acc: 0.7656\n",
      "Epoch 52/80\n",
      "384/384 [==============================] - 0s 226us/step - loss: 0.4334 - acc: 0.7865 - val_loss: 0.4941 - val_acc: 0.7656\n",
      "Epoch 53/80\n",
      "384/384 [==============================] - 0s 222us/step - loss: 0.4333 - acc: 0.7865 - val_loss: 0.4945 - val_acc: 0.7578\n",
      "Epoch 54/80\n",
      "384/384 [==============================] - 0s 219us/step - loss: 0.4324 - acc: 0.7943 - val_loss: 0.4904 - val_acc: 0.7734\n",
      "Epoch 55/80\n",
      "384/384 [==============================] - 0s 218us/step - loss: 0.4314 - acc: 0.7917 - val_loss: 0.4935 - val_acc: 0.7656\n",
      "Epoch 56/80\n",
      "384/384 [==============================] - 0s 213us/step - loss: 0.4317 - acc: 0.7943 - val_loss: 0.4941 - val_acc: 0.7656\n",
      "Epoch 57/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4312 - acc: 0.7943 - val_loss: 0.4928 - val_acc: 0.7734\n",
      "Epoch 58/80\n",
      "384/384 [==============================] - 0s 244us/step - loss: 0.4314 - acc: 0.7943 - val_loss: 0.4915 - val_acc: 0.7656\n",
      "Epoch 59/80\n",
      "384/384 [==============================] - 0s 218us/step - loss: 0.4316 - acc: 0.7969 - val_loss: 0.4988 - val_acc: 0.7656\n",
      "Epoch 60/80\n",
      "384/384 [==============================] - 0s 218us/step - loss: 0.4315 - acc: 0.7995 - val_loss: 0.4970 - val_acc: 0.7656\n",
      "Epoch 61/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 0s 219us/step - loss: 0.4315 - acc: 0.7917 - val_loss: 0.4989 - val_acc: 0.7656\n",
      "Epoch 62/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4304 - acc: 0.7943 - val_loss: 0.4984 - val_acc: 0.7734\n",
      "Epoch 63/80\n",
      "384/384 [==============================] - 0s 218us/step - loss: 0.4300 - acc: 0.7969 - val_loss: 0.4958 - val_acc: 0.7656\n",
      "Epoch 64/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4294 - acc: 0.7943 - val_loss: 0.4959 - val_acc: 0.7578\n",
      "Epoch 65/80\n",
      "384/384 [==============================] - 0s 220us/step - loss: 0.4290 - acc: 0.7995 - val_loss: 0.4935 - val_acc: 0.7656\n",
      "Epoch 66/80\n",
      "384/384 [==============================] - 0s 218us/step - loss: 0.4292 - acc: 0.7943 - val_loss: 0.4916 - val_acc: 0.7656\n",
      "Epoch 67/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4286 - acc: 0.7995 - val_loss: 0.4965 - val_acc: 0.7656\n",
      "Epoch 68/80\n",
      "384/384 [==============================] - 0s 226us/step - loss: 0.4285 - acc: 0.7995 - val_loss: 0.4933 - val_acc: 0.7812\n",
      "Epoch 69/80\n",
      "384/384 [==============================] - 0s 221us/step - loss: 0.4283 - acc: 0.7995 - val_loss: 0.4945 - val_acc: 0.7812\n",
      "Epoch 70/80\n",
      "384/384 [==============================] - 0s 217us/step - loss: 0.4290 - acc: 0.8047 - val_loss: 0.4996 - val_acc: 0.7656\n",
      "Epoch 71/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4281 - acc: 0.8047 - val_loss: 0.4969 - val_acc: 0.7734\n",
      "Epoch 72/80\n",
      "384/384 [==============================] - 0s 236us/step - loss: 0.4290 - acc: 0.8047 - val_loss: 0.4994 - val_acc: 0.7656\n",
      "Epoch 73/80\n",
      "384/384 [==============================] - 0s 221us/step - loss: 0.4281 - acc: 0.8021 - val_loss: 0.4934 - val_acc: 0.7734\n",
      "Epoch 74/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4276 - acc: 0.8021 - val_loss: 0.4987 - val_acc: 0.7734\n",
      "Epoch 75/80\n",
      "384/384 [==============================] - 0s 223us/step - loss: 0.4284 - acc: 0.7995 - val_loss: 0.4965 - val_acc: 0.7734\n",
      "Epoch 76/80\n",
      "384/384 [==============================] - 0s 226us/step - loss: 0.4265 - acc: 0.8099 - val_loss: 0.5006 - val_acc: 0.7656\n",
      "Epoch 77/80\n",
      "384/384 [==============================] - 0s 215us/step - loss: 0.4255 - acc: 0.8073 - val_loss: 0.4999 - val_acc: 0.7734\n",
      "Epoch 78/80\n",
      "384/384 [==============================] - 0s 219us/step - loss: 0.4262 - acc: 0.8021 - val_loss: 0.4953 - val_acc: 0.7812\n",
      "Epoch 79/80\n",
      "384/384 [==============================] - 0s 216us/step - loss: 0.4269 - acc: 0.7995 - val_loss: 0.4992 - val_acc: 0.7734\n",
      "Epoch 80/80\n",
      "384/384 [==============================] - 0s 217us/step - loss: 0.4249 - acc: 0.8073 - val_loss: 0.5007 - val_acc: 0.7734\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "history=model.fit(X_train, y_train, validation_split=0.25, epochs=80, batch_size=10)\n",
    "# calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XmYVOWV+PHvqaqurl6qF+iFpYEGAQFBARE1Oor7Mo4aY6JEE82ik30SJzOjmUwWk5kxM5nEzG+SSYzRLC7EmBjXUYlR4y6guACygzTN0gu9b7Wc3x/vbSiahu6mq7oK6nyep56ue+veqlPd1ffUe973vldUFWOMMeZQfOkOwBhjTOazZGGMMWZAliyMMcYMyJKFMcaYAVmyMMYYMyBLFsYYYwZkycKYYRCRahFREQkMYtvrReTF4T6PMelgycJkDRHZIiI9IlLWZ/1K70BdnZ7IjMl8lixMttkMLO5dEJE5QF76wjHmyGDJwmSb3wAfT1i+Dvh14gYiUiwivxaROhHZKiJfFxGf95hfRL4vIvUisgn46372/YWI7BCR7SLyXRHxDzVIERknIo+ISKOIbBCRGxIeWygiy0WkRUR2icgPvPUhEblHRBpEpElElolI5VBf25j+WLIw2eZVoEhEZnoH8auAe/ps8/+AYmAKcCYuuXzCe+wG4BJgHrAAuLLPvr8CosBUb5vzgU8fRpz3AzXAOO81/k1EzvEe+xHwI1UtAo4BHvDWX+fFPQEYDXwG6DyM1zbmAJYsTDbqbV2cB7wHbO99ICGB3KKqraq6Bfgv4GPeJh8BblfVbaraCPx7wr6VwEXAl1W1XVV3Az8Erh5KcCIyATgd+CdV7VLVlcCdCTFEgKkiUqaqbar6asL60cBUVY2p6gpVbRnKaxtzMJYsTDb6DfBR4Hr6lKCAMiAIbE1YtxUY790fB2zr81ivSUAOsMMrAzUBPwMqhhjfOKBRVVsPEsOngOnAe16p6ZKE9/UUsEREakXkP0QkZ4ivbUy/LFmYrKOqW3Ed3RcDf+jzcD3uG/qkhHUT2df62IEr8yQ+1msb0A2UqWqJdytS1eOGGGItMEpEwv3FoKrrVXUxLgl9D3hQRApUNaKq31bVWcAHcOWyj2NMEliyMNnqU8DZqtqeuFJVY7g+gH8VkbCITAJuYl+/xgPAl0SkSkRKgZsT9t0BPA38l4gUiYhPRI4RkTOHEpiqbgNeBv7d67Q+3ov3XgARuVZEylU1DjR5u8VE5CwRmeOV0lpwSS82lNc25mAsWZispKobVXX5QR7+ItAObAJeBO4D7vIe+zmu1PMW8AYHtkw+jitjrQb2AA8CYw8jxMVANa6V8RDwTVVd6j12IbBKRNpwnd1Xq2oXMMZ7vRZgDfA8B3beG3NYxC5+ZIwxZiDWsjDGGDMgSxbGGGMGZMnCGGPMgCxZGGOMGVBKp0MWkQtxozX8wJ2qelufx38InOUt5gMVqlriPXYd8HXvse+q6q8O9VplZWVaXV2dxOiNMebot2LFinpVLR9ou5SNhvLGeq/DTalQAywDFqvq6oNs/0Vgnqp+UkRGActxc+8osAI4UVX3HOz1FixYoMuXH2wkpDHGmP6IyApVXTDQdqksQy0ENqjqJlXtAZYAlx1i+8W4ydMALgCWqmqjlyCW4saWG2OMSYNUJovx7D+HTg375rbZj3eW7GTgz0PZV0Ru9KZqXl5XV5eUoI0xxhwolclC+ll3sJrX1cCD3lQLg95XVe9Q1QWquqC8fMCSmzHGmMOUyg7uGvafcK0KN3VBf64GPt9n30V99n1uqAFEIhFqamro6uoa6q5HrFAoRFVVFTk5NtmoMSZ5UpkslgHTRGQybrbMq3HTQu9HRI4FSoFXElY/hbvYS6m3fD5wy1ADqKmpIRwOU11djUh/jZWji6rS0NBATU0NkydPTnc4xpijSMrKUKoaBb6AO/CvAR5Q1VUicquIXJqw6WJgiSYMy/IuKvMdXMJZBtzqrRuSrq4uRo8enRWJAkBEGD16dFa1pIwxIyOl51mo6hPAE33WfaPP8rcOsu9d7Jvp87BlS6LolW3v1xgzMrL+DO5oLM7Oli66IjbtvzHGHEzWJwuA+tYuGlqTX7ppaGhg7ty5zJ07lzFjxjB+/Pi9yz09PYN6jk984hOsXbs26bEZY8xQpLQMdSQIaIRZspXaztFEY3kE/MnLn6NHj2blypUAfOtb36KwsJCvfvWr+22jqqgqPl//r3v33XcnLR5jjDlc1rLwB8HnJ0w7je2D+7Y/XBs2bGD27Nl85jOfYf78+ezYsYMbb7yRBQsWcNxxx3Hrrbfu3fb0009n5cqVRKNRSkpKuPnmmznhhBM49dRT2b1794jEa4wxWdOy+Pajq1hd29L/g7FuiEXoZDd5wcH/SmaNK+Kbf3PcYcWzevVq7r77bn76058CcNtttzFq1Cii0ShnnXUWV155JbNmzdpvn+bmZs4880xuu+02brrpJu666y5uvvnm/p7eGGOSyloWAD6XIHwaIxofmcvMHnPMMZx00kl7l++//37mz5/P/PnzWbNmDatXHzjfYl5eHhdddBEAJ554Ilu2bBmRWI0xJmtaFodsAaiiu96lLR5iV2AMx5QXpnwIakFBwd7769ev50c/+hGvv/46JSUlXHvttf2eKxEMBvfe9/v9RKPRlMZojDG9rGUBIIKESiigg66eKB09IzuMtqWlhXA4TFFRETt27OCpp54a0dc3xpiBZE3LYkChYnwd9RT5OqlvC1KQO3K/mvnz5zNr1ixmz57NlClTOO2000bstY0xZjBSdvGjkdbfxY/WrFnDzJkzB/cEGoed79LpK2BDpIxjx4QJBo7MhteQ3rcxJqtlwsWPjizig7xiQvE2IE5Hj/UHGGNML0sWiUIliMYppJPuaDzd0RhjTMawZJEoNwzip9TXQY8lC2OM2cuSRSLxQaiIMO30RG1iQWOM6WXJoq9QCX7i+KMd6Y7EGGMyhiWLvnLyAAhoD9G4laKMMQYsWRzIH0SBHKJJ6bdYtGjRASfZ3X777Xzuc5876D6FhYXDfl1jjEkmSxZ9iaC+IMEkJYvFixezZMmS/dYtWbKExYsXD/u5jTFmpFiy6IcEggSJJGX47JVXXsljjz1Gd3c3AFu2bKG2tpa5c+dyzjnnMH/+fObMmcPDDz887NcyxphUyZ7pPv7vZtj5zqA2lWgXefEofl8eBPwH33DMHLjotkM+1+jRo1m4cCFPPvkkl112GUuWLOGqq64iLy+Phx56iKKiIurr6znllFO49NJL7RraxpiMZC2L/ojgw13BLhkSS1G9JShV5Wtf+xrHH3885557Ltu3b2fXrl1JeT1jjEm27GlZDNAC2E9HIzRtZTsTmDqubNgvffnll3PTTTfxxhtv0NnZyfz58/nlL39JXV0dK1asICcnh+rq6n6nJTfGmExgLYv++N11I/zxCNHY8PstCgsLWbRoEZ/85Cf3dmw3NzdTUVFBTk4Ozz77LFu3bh326xhjTKpYsuiPlyyCkpwRUeBKUW+99RZXX301ANdccw3Lly9nwYIF3HvvvcyYMSMpr2OMMamQPWWoofDnoAg5ROiOxclPwlN+8IMf3K8PpKysjFdeeaXfbdva2pLwisYYkzzWsuiPCPiTd66FMcYc6SxZHIT4g+RK1KYqN8YYsiBZHPbw10Bvy+LImn32aLnyoTEms6Q0WYjIhSKyVkQ2iMjNB9nmIyKyWkRWich9CetjIrLSuz1yOK8fCoVoaGg4vAOoP4ifGJFo7Ig5AKsqDQ0NhEKhdIdijDnKpKyDW0T8wI+B84AaYJmIPKKqqxO2mQbcApymqntEpCLhKTpVde5wYqiqqqKmpoa6urqh79zTAR317NII8T2F+HxHxpnVoVCIqqqqdIdhjDnKpHI01EJgg6puAhCRJcBlwOqEbW4AfqyqewBUdXcyA8jJyWHy5MmHt/O2ZfDQR/jPnq/y+b/9AidOKk1maMYYc0RJZRlqPLAtYbnGW5doOjBdRF4SkVdF5MKEx0Iistxbf3l/LyAiN3rbLD+s1sOhlE4CoErq2NrQntznNsaYI0wqWxb91W36Fv8DwDRgEVAFvCAis1W1CZioqrUiMgX4s4i8o6ob93sy1TuAOwAWLFiQ3I6FgnI0kMfEaB1b6i1ZGGOyWypbFjXAhITlKqC2n20eVtWIqm4G1uKSB6pa6/3cBDwHzEthrAcSQUomMi23kc0NdolVY0x2S2WyWAZME5HJIhIErgb6jmr6I3AWgIiU4cpSm0SkVERyE9afxv59HSOjZCKTfPXWsjDGZL2UJQtVjQJfAJ4C1gAPqOoqEblVRC71NnsKaBCR1cCzwD+oagMwE1guIm95629LHEU1YkonURHfxZb69iNm+KwxxqRCSueGUtUngCf6rPtGwn0FbvJuidu8DMxJZWyDUjKJ/FgrdLfQ0N5DWWFuuiMyxpi0OOrP4B6WkomAGxG1u6U7zcEYY0z6WLI4FG/47ATZTWN7T5qDMcaY9LFkcSglvcmijoZ2a1kYY7KXJYtDyStFg4VUSR0NbdayMMZkL0sWhyICpZOY6LOWhTEmu1myGICUTGKir95aFsaYrGbJYiAlkxhPHQ1t1rIwxmQvSxYDKZlIPp30tCZ5okJjjDmCWLIYSLGbKNfftjPNgRhjTPpYshhI4RgAgp3WsjDGZC9LFgMJV7of0Xq6IkfW9biNMSZZLFkMxGtZlNNkZ3EbY7KWJYuB5ISI5BRRIZYsjDHZy5LFIETzK6iQJupt+KwxJktZshiM8BgqZY+1LIwxWcuSxSAEisdQQZOdxW2MyVqWLAYhUDTWK0N1pTsUY4xJC0sWgyBFY8mVCJ0tjekOxRhj0sKSxWAUunMt4i12FrcxJjtZshiMsDvXQmzKD2NMlrJkMRjeiXk5nbvTHIgxxqSHJYvB8Kb8yOuuT3MgxhiTHpYsBiM3TMSXR2m8kY6eaLqjMcaYEWfJYpC6QuVUiJ1rYYzJTpYsBilW4Kb8aLCzuI0xWciSxSBp4Rgq2ENju80PZYzJPpYsBilQPMY7i9taFsaY7GPJYpByS8dRKF00NzWlOxRjjBlxKU0WInKhiKwVkQ0icvNBtvmIiKwWkVUicl/C+utEZL13uy6VcQ5GsHgcAJHm2jRHYowxIy+QqicWET/wY+A8oAZYJiKPqOrqhG2mAbcAp6nqHhGp8NaPAr4JLAAUWOHtuydV8Q4obFN+GGOyVypbFguBDaq6SVV7gCXAZX22uQH4cW8SUNXeU6QvAJaqaqP32FLgwhTGOrDwWACkbVdawzDGmHRIZbIYD2xLWK7x1iWaDkwXkZdE5FURuXAI+yIiN4rIchFZXldXl8TQ++FNJmhTfhhjslEqk4X0s077LAeAacAiYDFwp4iUDHJfVPUOVV2gqgvKy8uHGe4A8kqJSJC87hQnJWOMyUCpTBY1wISE5Sqgb+9wDfCwqkZUdTOwFpc8BrPvyBKhPWcU4UgDqgfkLWOMOaqlMlksA6aJyGQRCQJXA4/02eaPwFkAIlKGK0ttAp4CzheRUhEpBc731qVVd6ic0bqHtm6bH8oYk11SlixUNQp8AXeQXwM8oKqrRORWEbnU2+wpoEFEVgPPAv+gqg2q2gh8B5dwlgG3euvSKppfafNDGWOyUsqGzgKo6hPAE33WfSPhvgI3ebe++94F3JXK+IYsXEmlvMLG9h6qywrSHY0xxowYO4N7CAJFYymRdvY0t6Q7FGOMGVGWLIYgd5Q7i7uj0c7iNsZkF0sWQ1Aw2p3q0dO0I82RGGPMyLJkMQQ5xe4s7liLJQtjTHaxZDEUhWMA8NmUH8aYLGPJYigKyojhsyk/jDFZx5LFUPj8tPhLyeuuT3ckxhgzoixZDFF7sIzCiCULY0x2sWQxRF2hckpijcTjNj+UMSZ7WLIYorg35ceeDpvywxiTPSxZDFXxeMqlmbpGuxa3MSZ7WLIYIn/FdADad7yX5kiMMWbkWLIYorxxswCI7rJkYYzJHpYshqikagYxFfwN69MdijHGjBhLFkOUn19ADZXkNW9IdyjGGDNiLFkchprABEo7Nqc7DGOMGTGWLA5Dfaiaip4aiNnlVY0x2cGSxWFoKZxCgCg0bU13KMYYMyIGlSxE5BgRyfXuLxKRL4lISWpDy1zdpVPdnbq16Q3EGGNGyGBbFr8HYiIyFfgFMBm4L2VRZbqyaQD07FqT5kCMMWZkDDZZxFU1CnwQuF1VvwKMTV1Yma2ktJxdWkKPnZhnjMkSg00WERFZDFwHPOaty0lNSJmvPJzLhvh4qLcylDEmOww2WXwCOBX4V1XdLCKTgXtSF1ZmqwjnskHHkdu0AdRmnzXGHP0Cg9lIVVcDXwIQkVIgrKq3pTKwTFYezmWDjicn2g6tO6EoaytyxpgsMdjRUM+JSJGIjALeAu4WkR+kNrTMNSo/yGbGuwUrRRljssBgy1DFqtoCXAHcraonAuemLqzM5vMJjfmT3ULduvQGY4wxI2CwySIgImOBj7Cvgzur+cNj6JACa1kYY7LCYJPFrcBTwEZVXSYiU4Csnna1vCjE+74qOzHPGJMVBtvB/TvgdwnLm4APpSqoI0FFOJf18XHMqF+d7lCMMSblBtvBXSUiD4nIbhHZJSK/F5GqQex3oYisFZENInJzP49fLyJ1IrLSu3064bFYwvpHhva2Uq88nMuqyBho2wWddolVY8zRbbBlqLuBR4BxwHjgUW/dQYmIH/gxcBEwC1gsIrP62fS3qjrXu92ZsL4zYf2lg4xzxPS2LACoz+qKnDEmCww2WZSr6t2qGvVuvwTKB9hnIbBBVTepag+wBLhsGLFmlN5zLQDr5DbGHPUGmyzqReRaEfF7t2uBhgH2GQ9sS1iu8db19SEReVtEHhSRCQnrQyKyXEReFZHL+3sBEbnR22Z5XV3dIN9KcpSHQ2zTCmK+oHVyG2OOeoNNFp/EDZvdCewArsRNAXIo0s+6vnNjPApUq+rxwJ+AXyU8NlFVFwAfBW4XkWMOeDLVO1R1gaouKC8fqKGTXBXhXOL4aC2YBPV2roUx5ug2qGShqu+r6qWqWq6qFap6Oe4EvUOpARJbClVAbZ/nbVDVbm/x58CJCY/Vej83Ac8B8wYT60gpD+cCsDtvCux4y+aIMsYc1YZzpbybBnh8GTBNRCaLSBC4GtdJvpd3ol+vS4E13vrShIstlQGnARk1RjWU4yccCrA6NB9ad8CuVekOyRhjUmY4yaK/MtNe3vUvvoA7mW8N8ICqrhKRW0Wkd3TTl0RklYi8hZuo8Hpv/Uxgubf+WeA2bzLDjFIRzuU1v9fg2bA0vcEYY0wKDeqkvIMYsO6iqk8AT/RZ942E+7cAt/Sz38vAnGHENiLKw7ms7whC5RxY/yc4/SvpDskYY1LikC0LEWkVkZZ+bq24cy6yWkU4RF1bN0w7F7a9Cl0t6Q7JGGNS4pDJQlXDqlrUzy2sqsNplRwVysO57G7pRqeeC/EobHou3SEZY0xKDKfPIutVhHPpjMRorzgRcous38IYc9SyZDEMe4fPtsdgyiLXb2FDaI0xRyFLFsNQEQ4BUNfaDdPOg9Za2J1xg7aMMWbYLFkMw96WRWs3TPUuHLjeSlHGmKOPJYthqPCSRV1rNxSNg8rZsOFPaY7KGGOSz5LFMJTk55DjF9eyANe6eP8VG0JrjDnqWLIYBhGhvDDXtSzA9VvEo7D5+fQGZowxSWbJYpjKw7nsbu1yCxNOhmAY1j2V3qCMMSbJLFkMU3k4xO4Wr2Xhz4FjL4LVj0CkM72BGWNMElmyGKYp5QVsbmgnFvfOr5j/MehudgnDGGOOEpYshmlaRSE90ThbG9rdikmnQ2k1vPmbtMZljDHJZMlimKZXhgFYt6vNrfD5YN61sOUFaNyUxsiMMSZ5LFkM09SKQgDW72rdt3LuNSA+ePOeNEVljDHJZclimApyA1SV5rE2MVkUjXPnXKy8D2LR9AVnjDFJYskiCaZXhlnfW4bqNf/j7nKrG59JT1DGGJNEliySYFplIZvq24jE4vtWTr8QCsrhjV+nLzBjjEkSSxZJML0iTCSm+0ZEgTvn4oSrYd2T0LY7fcEZY0wSWLJIggNGRPWa93E3/cdb96chKmOMSR5LFkkwtaIQEViX2MkNUD7dTQHyxm/sokjGmCOaJYskyAv6mVCaf2AnN7iO7ob1sO21kQ/MGGOSxJJFkkyvDB/YsgCYdTkEC62j2xhzRLNkkSTTKwvZXN9OTzS+/wO5hTD7Q7DqIbvOhTHmiGXJIkmmV4aJxpUtiSOies2/DiId8O7vRz4wY4xJAksWSTKt0k370W8pavx8qJhlkwsaY45YliyS5JjyQnzSz/BZABHX0b19BexaNfLBGWPMMFmySJJQjp9JowtYt7OflgXA8VeBP+iG0RpjzBEmpclCRC4UkbUiskFEbu7n8etFpE5EVnq3Tyc8dp2IrPdu16UyzmSZVlHIut0HSRb5o2DGJfD2Eoh0jWxgxhgzTClLFiLiB34MXATMAhaLyKx+Nv2tqs71bnd6+44CvgmcDCwEvikipamKNVmmV4bZ2tBBdzTW/wbzPwade2Dpv0AsMrLBGWMyV91aaNg49ONCPAbbXof1f0pNXAkCKXzuhcAGVd0EICJLgMuA1YPY9wJgqao2evsuBS4EMnrejGmVhcTiyqa6dmaOLTpwg8mLYOGN8PodsP0NuPIuKJ004nEac8TonflAJL1xdDbBil/CrEth1JQDH9+zFdp2wYSFQ3veWASe+md4/WduWfxQXAUVM+H8f4WyqQfu090K7z0O65+GjX92X0DLZ8K0c4f8toYilcliPLAtYbkG11Lo60MicgawDviKqm47yL7j++4oIjcCNwJMnDgxSWEfvn1zRLX2nyx8Prj4P2HSafDIF+FnfwWX/o/7ABqTjZ65Fdb+H8y8FOZcCWXTXIKofdPNqfbOgxDthqKx7joxRVUw+wp3vZiRSiCdTfCbD0LtG/Dn78CJn4Az/xEKK1xr4IX/greWgMbhqt/AzL/Zf/9oDzx+k5sn7qRPQ9UCt751F/zuenj/ZTj5MzDmeHd1zT2bXRL4xXnw0Qdgwkn7nmvHW/DAx2HPFiiogOkXuSQx5ayU/xpSmSz6+0v2nSDpUeB+Ve0Wkc8AvwLOHuS+qOodwB0ACxYsSPvkS1PKC/D7pP9pPxIddzmMPQEe/CQ88DG47Ccw75qRCdKYTLHuaXegLa2G578Hz9/m/i+i3VD3HvhzYcZfQ3gMtNS668Osfwreus/NuXbW12DymYefNDqbwBdwJ84edJs9LlHsWgWX/68r+Sy/y13YbNIH3PVq/EFXMahZBr+/Aa5/HKpOdPvHIvDgJ+C9xyCnwCXAcfNg9pXwyv+4GD70C5coEzVshHs+BL/6G1eBOPYi17L5v3+C/NHw8Yeh+gz3BXSEpDJZ1AATEpargNrEDVS1IWHx58D3EvZd1Gff55IeYZLlBvxMLivg3drmgTceNRk++RTc92F49O/cP0z1aSmP0ZiM0FYHD38OKo6DG/4MnY1uloNVD0FOPlxyOxz3Qcgr2X+/aA+svAf+8n349WVQdZJLJpEuiHZBINedBDvjkkMfSHe+C7+53LUGzv8unLD4wKTTuQd+fTnsXg1X3QPTL4C5H4UPfNG1MDa/AKd+Hk79IoQr3Xu68xy4/yr49J+gaPy+RHHRf8Lcxa4F8vrP4el/hpJJ8OmlMGbOgfGNPgY+tRTu+wj89hpXjdjyAhxzNlzxcygoG/7fYIhEUzQbqogEcKWlc4DtwDLgo6q6KmGbsaq6w7v/QeCfVPUUr4N7BTDf2/QN4MTePoz+LFiwQJcvX56S9zIU33pkFfe//j4rv3E+eUH/wDt0NrnmZnsdfPoZ9yExJp12vuu+wXfu8W5NMHYunP4V8B/k+2V3KzRvh+YaaN8NlcdB5Wzw9fM/oAr3Xw0bn4Ubn3XbDlWky8239sav3AE/kAuBELRsh6b3oWy6i3fOh921ZRJtWwb3fsjN2VY0zrUIJp0Of/1frg+xdqWb+POtJdC4Ea66F6afP7i46ta5/+fCCig/FtY8ChfeBqd8dv/3v+td9wUxN3zo5+tph999wvVPLLoFzvhq/7/TYRCRFaq6YMDtUpUsvCAuBm4H/MBdqvqvInIrsFxVHxGRfwcuBaJAI/BZVX3P2/eTwNe8p/pXVb37UK+VKcnipQ31XHPna/z84ws4b1bl4HZq2Oi+kRSUu28Tfb9NmezT3eYOYlMWjVxtvqsFnv0319mqcQjkQV4pBAvczMlTFsGH7oKC0W57VXjnd/DMd6D5/QOfL7fYlWqqT3et5so5Ltks+4Wr4fc9iCZDPAar/wgv/MAdkMPjXInn+I+45LX5ebj/o64l8PGHXR/Im7+Gpd+EnjZAIO6NSBo9zcU41I7jLS+6Fkk8Ahf8m2t9DOs9xV0CDo8Z3vMcREYki5GUKckiEosz/ztLuXj2WL535fGD37H3AzbpA3D1fYeuo5rMFou6A9ar/+vOrznnmzBm9tCe43fXu5JMMg42idrr4fn/cAf5sukw8RR3626Fp//Fjeg56VOw6Gv7kgK4k0kf/3sorHSduD4/PPEP8P4rrgY/63I3iqd4gkswO95yZZMtL7pv5wDBMEw8Gba85D7n1zyYupq7KqxfCsvudP0K8agbMdS4EUZPhY/90SWMxN/LS7e70UgTTnajmoZT6tn4Z+hoPLAvIgNZskijL97/Jq9srOf1r52LzzeEb4Ur74OHP++G5l15l+vsM0eOaDesvBde+pEbrVI23V1St7sF5l0LZ319/wPUwax5zNWpi8a7jt2P/tbVyw+mrQ7WPAyFY+DYi/s/APe0wys/cbFFOlzHcUutO6j3fpMeOxcu+QGMP7H/19m+An77MXdgjUcgVALnfgvmfezQB/2WWtj6Mmx9ySWKSIer6afom/IB2utd4n3nd65c9eFfuSRuAEsWafXwyu383ZKV/OFzH2D+xCGeS7j5BfjDDdDR4DreFt7oRoFs/ou7hce6YXuB3NQEn806m9y35YoZMPeaAw9mDRtdPXzymQceHJtr4L6rXOlj/Ilw+k1B+p/AAAAYQklEQVTuwN3V5DpjX/+Zq6kffxXMvASq/+rAWjq4PoIfn+xq3tc/7kbDNGyETz29f20/2uPq2Cvvc/0L8ahbXz7T1bWP+6D7dv3+K7DmEXewbK9zHb/nfNNdxREg0unO+elqgukXDlwPb6uDx7/iPoeLbrGD7lHAkkUaNXdEmP/dpfztGVP4xwtnDP0J2hvcSJF1T7pmf9sutz5UDF3NbgTIR37tOueORt2trl5+sM7UVIhF4N4rXULWuCtHTL/AjZnf8bY7MPeWUyadBpf+v32DEWpXukTR0w5X/Mwlib79DA0bXX/A2ifcN+tQsRsjf8pnYdzcfds9/HlYeb/r+B17gvtW/vOz3RDPTz7phnCuftidlNXV5D4fx18FJ1wNu1bDX/4T6tdC6WTXoulocElq6rluFM/EU0bm92mOGJYs0mzxHa/S0N7N01858/CeQNXVWzc/DxNOgclnuA66NQ/DHz/vOh0//Muja7htPA7LfwF/+parf19yO0w6dfD7bn4e3rwHmre5k5xmXb5/C6B+A7z2v26c+ulfgZw8t14VHvsKrLjbnfMy8RQ3nfzK+1yiDoRcS2D6Be6b99JvQawHzv0mlEyE33/aPedHH4DK/ma0SdDTAZuedaWm9x6H7mZ3cayzv+5KV7/5oGuVnPvNffvUvgl3XQTRTrecWwwzLobjrnBDKROTajzuPiOv3+lKXjMvhWnnuc+LMf2wZJFmv3hxM995bDXP/8MiJo1O8j/q7vdcTbtxM3zgC3Di9f1PQZAqXS3uBKGyaTDtguR0Utavd2e1v/+KOzDv2epG2Jx4vauL5x2knNf0vvsmvvIedz9U4g7cjRvd+PWzvg4lE9zJX6seAl8OxLpdJ+dlP3Edrq/8BJ66xSWQc7+177ljEVdWKjsWgvn71rfUwqNfduUfcB28i387uP6IRF3N8NJ/wys/dn0AuWHIL4PPvAg5of23Xb/UtUqOvdiVwQLBob2WMQdhySLNtja0c+Z/Pse/XDKLT50+Ofkv0NXsRqe8+3tXNqn+K3cy0sy/OfBAM1SdTfDqT1xZZd7HXA2/13uPw+NfhVbv/MryGXDal92oj/5q8Iei6jpYV/0BXv2pi/uCf3cnPvW0w3P/7uLIL3M1+LEnwNjjXavjvSfc2bBbXnDPNWWRi3XGJS6Odx50++/Z7B4PFrqpFk79vDvJ6uEvuhbIcR90SWTm37iOz8EmPlV4+7euRHX21/dPJkPVutOdwbzqIZd0JvY3K44xqWHJIgOc/8PnKSvM5b4bUlgnbql15ZI3fg1NW10tfPaVbvTNuHlDG6Mf6YJlP3cdsl3Nrk4ej7ga/fyPu0Sx5hFXDrvkh65s8uIP3cG3d86eYy92ww776yiNx12MdWvdQX7No25Z/G5+rAu/d+C389o33Rj4mmWu1p9o1BQ44aNwwlWuHNRXLOIO6B0NLpEkdsZ2t7py17I73e/p+ieGd8A35ghlySID/MeT7/Gzv2zija+fR3H+EL91D1U8Dlv+Am/e6w7o0S43MqZqgeuIHXWMKxuVTT/wQN66032rfeUnrvRzzDlw3rfdiJc373Fz4TRtdbX7M//JdZT2tiJ6x7O/9lPXORyPuDJQ9V+514l0uoN8R4PrM+itu/ty4JizXE392Iv3H9Pf7/uLuU7inW+78tvkM1xSGu4Ja7tWu5ZKqJ+JH43JApYsMsAb7+/hip+8zI+unstlcw+YNDd1OptcaefdP7gJ2drr9j0WDLsEMuFk9017zaPuxCkUxs2Hc77hDuKJ4nHY9qob93+oKdW7mmHDM24W0W2vuYSSk+dGNoWK3fQH5ce60lXFzIGnOjDGpJwliwwQjyunf+/PVBaH+MNnP4Cka07+rhbX4Vu31pVz3n8Ndq9yfR1l091onOOu2Df23hiTNQabLEZwIHv28fmEL5w9ja899A7Prt3N2TOGOFomWUJFri4/bp4bjw8ugXTUu/H46b6wjDEm443cZOhZ6sMLqpg0Op/vP7WOeDyDWnGhItdBbInCGDMIlixSLMfv48vnTmP1jhb+792d6Q7HGGMOiyWLEXDpCeOZVlHID5auJZZJrQtjjBkkSxYjwO8T/v786Wysa+ehN7enOxxjjBkySxYj5ILjxjBnfDE/emYdPdF4usMxxpghsWQxQkRc62JbYyc/eW5DusMxxpghsWQxgs6cXs4V88Zz+5/W8/Qq6+w2xhw5LFmMIBHh366YwwlVxXzltytZt6s13SEZY8ygWLIYYaEcPz/72ALycwPc8OvlNHX0pDskY4wZkCWLNBhTHOKn157IjqYuvnj/m3RFYukOyRhjDsmSRZqcOKmU714+mxfW13POfz3PI2/VcrTM02WMOfpYskijj5w0gftuOJnivBy+dP+bXPG/L7NsS6MlDWNMxrFZZzNALK78/o0avv/UWna3djOlrIC/Pn4slxw/jumVhembrdYYc9SzKcqPQO3dUR5eWctjb9fy6qYG4gpTKwq5ePYYLpozlhljwpY4jDFJZcniCFfX2s2T7+7giXd28tpmlziqR+fzoflVfOL0yRTm2uzyxpjhs2RxFKlv6+bpVbt44p0dvLihnlEFQT636BiuPWUSoZx+rnVtjDGDZMniKPXWtia+//RaXlhfz5iiEH975hQ+vGCCtTSMMYdlsMkipaOhRORCEVkrIhtE5OZDbHeliKiILPCWq0WkU0RWerefpjLOI8kJE0r4zadO5v4bTqGqNI9vP7qaU/7tGb796Cq21LenOzxjzFEqZS0LEfED64DzgBpgGbBYVVf32S4MPA4EgS+o6nIRqQYeU9XZg329bGlZ9LVyWxO/enkLj71dSySmlOTnUBAMUJgbIBwKcMb0cq6YP56q0vx0h2qMyUCZcA3uhcAGVd3kBbQEuAxY3We77wD/AXw1hbEcteZOKGHuVXO55eIZ/OGN7dQ2ddLWHaW9O8ru1m5+sHQdP1i6jlOmjOLiOWPpicbZ3drN7pYuABYvnMjCyaNslJUx5pBSmSzGA9sSlmuAkxM3EJF5wARVfUxE+iaLySLyJtACfF1VX+j7AiJyI3AjwMSJE5MZ+xGnIhziM2cec8D6bY0dPPTmdv7wRg3feHgVAMGAj4pwLm3dUf64spZ5E0v42zOO4fxZlfh8ljSMMQdKZbLo76izt+YlIj7gh8D1/Wy3A5ioqg0iciLwRxE5TlVb9nsy1TuAO8CVoZIV+NFkwqh8vnTONL549lRq9nRSFMqhKC+AiNDZE+PBFdu444VNfOaeFYwqCDKuJERlOERlcYjivByCfh/BgI/cgI95E0uZP7HEWiHGZKFUJosaYELCchVQm7AcBmYDz3kHnzHAIyJyqaouB7oBVHWFiGwEpgPZ1ymRJCLChFH791vkBf187NRqFi+cyJOrdvLCunp2tXZR29zFm9uaaO2KEIntn4NPmFDCJ0+r5uI5Y8nx22wxxmSLVHZwB3Ad3OcA23Ed3B9V1VUH2f454KteB3c50KiqMRGZArwAzFHVxoO9XrZ2cKdaPK70xOJ09MR4/O1a7n5pC5vq2xlTFOLESaVUFoUYU5xLZVGIorwcwrkBCkMBikI5VBaF8FtZy5iMlvYOblWNisgXgKcAP3CXqq4SkVuB5ar6yCF2PwO4VUSiQAz4zKEShUkdn08I+fyEclwr5JqTJ/Hcut3c99r7rNnRwrNrd9PR0/8U6wGfML40jwml+Uwcnc+0ikKmVYSZXllIeTiXaFyJxOJEokow4CMvaCcYGpOp7KQ8MyyqSmt3lN0tXbR0RWnritLWHaWpI0LNng627elkW2MHWxraaeqIHPK5Qjk+RhfkMqogSFlhkIpwiIqiXMrDuQB0RWJ0ReLE4spx44o4qXoUpQXBkXibxhy10t6yMNlBRFyneSjnkNupKvVtPazf1cr63W00tHUTDPjI8fsI+H10R2Psae+hob2HxvYe6tq6ebe2hYa2buKH+D4zvbKQOeNLEIFILE5PNI7PJ0wozWfS6HwmjcpnUlkBY4tCB4z06onGeb+xndyAn8qiEMGA9cEYczCWLMyIEBHKw66V8IGpZYPeLxqL09jRgyCEcnyEcvzEVXmnppnXNjfy+uZGXtxQh1+EYMCN3OqJxnl61c79OudDOT6qRxdwTHkh0Xic9bvb2NrQQczLRCJQEc6lqjSfOeOLOal6FCdVl1JRFEr678KYI5GVocxRKRZXdjR38n5DB5sb2tlU186mujY217cT8PuYWl7I1IpCppQXEI0p25s62d7UyfuNHbxT00ynd6nbqtI8RhUEycvxkx/0E/D7aO6I0NjRw572HkSEkyeP4rSpZZw2dTQV4RBbGtrZXO9u3ZEYecEAeTk+8oMBJo7OZ9a4ogFbYsaMFCtDmazm9wlVpflUleYPqSUDrpy1qraFZZsbeXt7M61dETp6YtS39RCJxSnJz2F6ZSGl+UE6e2K8vLGBx9/ZMaTXmDQ6nxljwsTi0NzZw56OCJ09McaVhKgeXUB1WQETRuVTmOsnLydAQa4fQWjujOy9lRUGOWN6uc08bEaEJQtj+sjx+9w0KhNKBrW9qrKpvp2XN9TT1BFhcnnB3gN+QdBPVyROZyRGe3eUDXVtrK5t4d3tzazd1UrQ76M0P8i0ikJCOX627+nkuXV11K2oGdRrF+YGOP+4Si49YRwnVJVQkBuwvheTElaGMiYDtXZF2NHcRXt3lM6eGB09MeKqFOflUJIfpDgvh/W7W3n0rVr+792dtHZF9+4b9PsoDAUYVxJiSlkhk8sKqC5zJ2R29rjEFYnFKc7LYVRBkFEFQcKhAKqufNd7SPD7hIBf8PuEsoJcivOtdHY0sutZGJMluqMxXlxfz9aGDtq7o7T1uCHM2/Z0srm+jZo9nSTj33xscYgZY8LMGFvErLFFzB5fzKRR+Taf2BHO+iyMyRK5AT/nzKw86ONdkRjbmzrxi5AX9BMK+An4Xf9HY3sPezp6aO2K4hPwieATQXGtjGg8TjSm7Grp4r2drazZ0cKLG+r3jjQL5waYObaIgF9o63ZJqqMnRlFegLLCXMoKcynJzyESi9MdidMddS2bjp59LaZYXAn4hRy/G0rt9wk+AUEQgarSfI6vKmZOVTGzxhZZH02aWMvCGDMkPdE463e3smp7C+9sb2bNjhZEXP9JYSiHUMBHc2eE+rZuGtp7aOqI7J2MMpTjJzfgoyAYIC+4b4RZNBZ3CSUaJ66uFBZXJR6HTfXt1Ld1A640NqogyKj8IKUFroxWWRRiXHEeY4pDjC0OUR52Saog4eqRqkp3NI7fJzanWR9WhjLGHBVUlZ0tXbxd08yq7c3sbu1mT0cPe9ojNLR3s7O5i/Z+ppzJy/FTkBugy2vJ9J7cWVaYy9jiEGOKQxSFcgh4fTM5fjflTEHQT34wQG6Oj13NXWxp6GBrQzu7Wrrd0GevDFdZHGLD7jbW7GhhdW0LzZ0Rjh0TZubYMDPGFDG5rICyQjcjQTDgEuL2pk4217ezrbGDaZVhFlaPSnsZz5KFMSYrqCotXVF2Nnexo7mT+rYe6tu6qW/tpr0nSl5OgPygn7ygn0gszq6WLnY0d7GzuYvWrujeUltPLE5XJLbfyZw+gXEleUwuK6C8MJfNDe2s3dm633xoZYW5zBpXRHFeDut2trKxro1on2kHwqHAAc8NML4kj8vmjuPyeeOZVlF4yOn/43GXNLc0tOMX4aQkJRrrszDGZAURoTgvh+K8HI4dEx728/VE465PJRJjVEGQ3MD+fSTxuLK1sYOdzV1MrSjcO3dZr+5ojA2729jW2Eljew8NXjkuL+hnclkBk8sKGF+Sx7ItjTz05nZ+9pdN/OS5jYwuCHLc+GJmjyvimPJCGtq7qdnTSc0ed7Lo+40d9ETje1+nqjSPjyyYwIcXVDG2OG/Y73sg1rIwxpg0qmvt5qlVO3m7pol3trewflfr3pZJUSjgnVyaR3VZgTffWQEN7d08sHwbL21owCdw0Zyx/M/ieYd1YTJrWRhjzBGgPJzLtadMAiYBbvRazZ5OysO5FOcd/NyWy+aO5/2GDn63Yhtx1ZRfwdKShTHGZJBQjp+pFYWD2nbi6Hz+/vxjUxyRY2PIjDHGDMiShTHGmAFZsjDGGDMgSxbGGGMGZMnCGGPMgCxZGGOMGZAlC2OMMQOyZGGMMWZAR810HyJSB2wdxlOUAfVJCieZMjUuyNzYMjUuyNzYMjUuyNzYMjUuGFpsk1S1fKCNjppkMVwisnww86OMtEyNCzI3tkyNCzI3tkyNCzI3tkyNC1ITm5WhjDHGDMiShTHGmAFZstjnjnQHcBCZGhdkbmyZGhdkbmyZGhdkbmyZGhekIDbrszDGGDMga1kYY4wZkCULY4wxA8r6ZCEiF4rIWhHZICI3pzmWu0Rkt4i8m7BulIgsFZH13s/SNMQ1QUSeFZE1IrJKRP4ug2ILicjrIvKWF9u3vfWTReQ1L7bfikhwpGPz4vCLyJsi8liGxbVFRN4RkZUistxblwl/zxIReVBE3vM+b6dmSFzHer+r3luLiHw5Q2L7ivfZf1dE7vf+J5L+OcvqZCEifuDHwEXALGCxiMxKY0i/BC7ss+5m4BlVnQY84y2PtCjw96o6EzgF+Lz3e8qE2LqBs1X1BGAucKGInAJ8D/ihF9se4FNpiA3g74A1CcuZEhfAWao6N2E8fib8PX8EPKmqM4ATcL+7tMelqmu939Vc4ESgA3go3bGJyHjgS8ACVZ0N+IGrScXnTFWz9gacCjyVsHwLcEuaY6oG3k1YXguM9e6PBdZmwO/tYeC8TIsNyAfeAE7Gnb0a6O/vPILxVOEOIGcDjwGSCXF5r70FKOuzLq1/T6AI2Iw38CZT4uonzvOBlzIhNmA8sA0YhbtM9mPABan4nGV1y4J9v+heNd66TFKpqjsAvJ8V6QxGRKqBecBrZEhsXqlnJbAbWApsBJpUNeptkq6/6+3APwJxb3l0hsQFoMDTIrJCRG701qX77zkFqAPu9kp3d4pIQQbE1dfVwP3e/bTGpqrbge8D7wM7gGZgBSn4nGV7spB+1tlY4oMQkULg98CXVbUl3fH0UtWYuvJAFbAQmNnfZiMZk4hcAuxW1RWJq/vZNF2ft9NUdT6uBPt5ETkjTXEkCgDzgf9V1XlAO+kphR2UV/u/FPhdumMB8PpILgMmA+OAAtzftK9hf86yPVnUABMSlquA2jTFcjC7RGQsgPdzdzqCEJEcXKK4V1X/kEmx9VLVJuA5XL9KiYgEvIfS8Xc9DbhURLYAS3ClqNszIC4AVLXW+7kbV3tfSPr/njVAjaq+5i0/iEse6Y4r0UXAG6q6y1tOd2znAptVtU5VI8AfgA+Qgs9ZtieLZcA0b+RAENe8fCTNMfX1CHCdd/86XH/BiBIRAX4BrFHVH2RYbOUiUuLdz8P986wBngWuTFdsqnqLqlapajXuc/VnVb0m3XEBiEiBiIR77+Nq8O+S5r+nqu4EtonIsd6qc4DV6Y6rj8XsK0FB+mN7HzhFRPK9/9Pe31nyP2fp7CjKhBtwMbAOV+f+5zTHcj+u7hjBfcv6FK7O/Qyw3vs5Kg1xnY5rxr4NrPRuF2dIbMcDb3qxvQt8w1s/BXgd2IArGeSm8e+6CHgsU+LyYnjLu63q/dxnyN9zLrDc+3v+ESjNhLi82PKBBqA4YV3aYwO+Dbznff5/A+Sm4nNm030YY4wZULaXoYwxxgyCJQtjjDEDsmRhjDFmQJYsjDHGDMiShTHGmAFZsjBmCEQk1mf20aSdYSwi1ZIw47AxmSQw8CbGmASd6qYWMSarWMvCmCTwrg/xPe/aGq+LyFRv/SQReUZE3vZ+TvTWV4rIQ951ON4SkQ94T+UXkZ971yd42jsr3Zi0s2RhzNDk9SlDXZXwWIuqLgT+BzcPFN79X6vq8cC9wH976/8beF7ddTjm486kBpgG/FhVjwOagA+l+P0YMyh2BrcxQyAibapa2M/6LbiLMG3yJl3cqaqjRaQed72DiLd+h6qWiUgdUKWq3QnPUQ0sVXfBGkTkn4AcVf1u6t+ZMYdmLQtjkkcPcv9g2/SnO+F+DOtXNBnCkoUxyXNVws9XvPsv42adBbgGeNG7/wzwWdh78aaikQrSmMNh31qMGZo876p8vZ5U1d7hs7ki8hruS9hib92XgLtE5B9wV4H7hLf+74A7RORTuBbEZ3EzDhuTkazPwpgk8PosFqhqfbpjMSYVrAxljDFmQNayMMYYMyBrWRhjjBmQJQtjjDEDsmRhjDFmQJYsjDHGDMiShTHGmAH9f1poLhtiXb/zAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.17944704, -0.1268486 , -0.16548371, -0.1528258 ,  0.10589679,\n",
      "        -0.22528031,  0.18850549,  0.02279594,  0.19528264,  0.09929803,\n",
      "         0.21612364,  0.11536899],\n",
      "       [ 0.22669053, -0.22738375, -0.3068772 , -0.16041665, -0.25797656,\n",
      "        -0.28671348,  0.32316694, -0.28203213,  0.23906435, -0.3025586 ,\n",
      "         0.26038638,  0.29633972],\n",
      "       [-0.08791666, -0.00453607,  0.21873218,  0.23259383, -0.12065344,\n",
      "         0.20591204, -0.1824468 , -0.07903567, -0.08990007, -0.14296691,\n",
      "        -0.17719662, -0.13512915],\n",
      "       [ 0.06939089, -0.19020054,  0.02929879, -0.05542013, -0.17758496,\n",
      "         0.1143278 , -0.13512026, -0.23300922,  0.05644024, -0.22353129,\n",
      "        -0.06656788, -0.1708364 ],\n",
      "       [-0.0189459 ,  0.08797636, -0.1675888 , -0.02576965, -0.00736026,\n",
      "        -0.0782578 , -0.05744631,  0.08781216,  0.01778825,  0.08980038,\n",
      "        -0.10353105,  0.01491554],\n",
      "       [ 0.19739224, -0.09518069, -0.16897312, -0.18334919, -0.07589478,\n",
      "        -0.21166104,  0.13868059, -0.12690467,  0.21763942, -0.07185132,\n",
      "         0.08543021,  0.15997578],\n",
      "       [-0.01792731, -0.33984128,  0.00228898, -0.08008393, -0.4297564 ,\n",
      "        -0.00314528, -0.08912827, -0.13960694, -0.03182707, -0.37276924,\n",
      "        -0.02169535, -0.14418577],\n",
      "       [-0.03054144, -0.49614045, -0.38865805, -0.43352672,  0.12105205,\n",
      "        -0.34675246, -0.09643701,  0.00870332, -0.02526977,  0.0341501 ,\n",
      "        -0.14280398, -0.03522151]], dtype=float32), array([0.17339617, 0.12372766, 0.1808172 , 0.12145414, 0.34682927,\n",
      "       0.25028846, 0.10340662, 0.20281301, 0.17960556, 0.3462194 ,\n",
      "       0.13223255, 0.11118129], dtype=float32)]\n",
      "[array([[ 0.3300192 ,  0.26224345, -0.02013936, -0.0436165 , -0.06794322,\n",
      "         0.29638022,  0.32879788, -0.06651188],\n",
      "       [ 0.00702399, -0.002937  ,  0.38041714,  0.33649033,  0.3453728 ,\n",
      "         0.01538935, -0.01049868,  0.37561515],\n",
      "       [-0.1316587 , -0.10880845,  0.3764829 ,  0.36492005,  0.3918166 ,\n",
      "        -0.11439393, -0.10283671,  0.33255336],\n",
      "       [-0.05831081, -0.08515099,  0.29396382,  0.3510806 ,  0.35613713,\n",
      "        -0.08471421, -0.0816391 ,  0.3131763 ],\n",
      "       [-0.32396752, -0.27026767,  0.3122935 ,  0.37819636,  0.3975664 ,\n",
      "        -0.31664604, -0.2791304 ,  0.32360393],\n",
      "       [-0.26041335, -0.24770129,  0.3826933 ,  0.38473853,  0.34840313,\n",
      "        -0.25025216, -0.2474136 ,  0.36212218],\n",
      "       [ 0.29181924,  0.37573716, -0.25031617, -0.27695754, -0.2517257 ,\n",
      "         0.3498427 ,  0.35442612, -0.2075096 ],\n",
      "       [-0.00097663,  0.02408827,  0.24137972,  0.25262997,  0.22681314,\n",
      "        -0.00432905, -0.04399239,  0.16513027],\n",
      "       [ 0.30155635,  0.2589193 , -0.04355639, -0.03079697,  0.00206066,\n",
      "         0.32013774,  0.304454  , -0.00787799],\n",
      "       [-0.3015208 , -0.36135116,  0.3827409 ,  0.38588   ,  0.40501666,\n",
      "        -0.30916414, -0.33534178,  0.35082176],\n",
      "       [ 0.37818927,  0.3679086 , -0.20644316, -0.16844988, -0.23096807,\n",
      "         0.323694  ,  0.3646811 , -0.20951322],\n",
      "       [ 0.33918026,  0.2992759 , -0.05828752, -0.0609819 , -0.08741147,\n",
      "         0.35648954,  0.333038  , -0.06674751]], dtype=float32), array([0.16570492, 0.17042536, 0.17946118, 0.17864856, 0.19332597,\n",
      "       0.16300361, 0.15563396, 0.17660134], dtype=float32)]\n",
      "[array([[ 0.34733322],\n",
      "       [ 0.38557342],\n",
      "       [-0.38650957],\n",
      "       [-0.3859043 ],\n",
      "       [-0.35652438],\n",
      "       [ 0.3905331 ],\n",
      "       [ 0.37939465],\n",
      "       [-0.39188316]], dtype=float32), array([-0.00646009], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)  \n",
    "p_labels = [round(x[0]) for x in predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7421875\n",
      "[[141  26]\n",
      " [ 40  49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.84      0.81       167\n",
      "         1.0       0.65      0.55      0.60        89\n",
      "\n",
      "    accuracy                           0.74       256\n",
      "   macro avg       0.72      0.70      0.70       256\n",
      "weighted avg       0.74      0.74      0.74       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\", metrics.accuracy_score(y_test, p_labels))\n",
    "print(confusion_matrix(y_test,p_labels))  \n",
    "print(classification_report(y_test,p_labels))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
